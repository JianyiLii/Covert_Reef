[
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "🌊 Project Proposal 🪸",
    "section": "",
    "text": "Clepper, a lead investigator on Oceanus, has been closely monitoring the closure of Nemo Reef. Over the span of two weeks, he and his intern listened to and analyzed radio communications and utilized his investigative tools to uncover a complex web of expedited approvals, hidden communication, and secretive logistics. Their investigation revealed a story involving high-level Oceanus officials, Sailor Shift’s team, local influential families, and the Green Guardians, who are a local conservationist group, pointing towards possibilities of corruption and manipulation. Amidst this investigation, Nadia Conti, a known figure formerly entangled in illegal fishing operations, has resurfaced as a person of interest. The project aims to develop new and novel visual analytics techniques to support Clepper’s investigation in uncovering the full extent of the events on Oceanus."
  },
  {
    "objectID": "proposal.html#website-look",
    "href": "proposal.html#website-look",
    "title": "🌊 Project Proposal 🪸",
    "section": "Website Look",
    "text": "Website Look"
  },
  {
    "objectID": "proposal.html#shiny-applications-on-networks-and-visualisations",
    "href": "proposal.html#shiny-applications-on-networks-and-visualisations",
    "title": "🌊 Project Proposal 🪸",
    "section": "Shiny Applications on Networks and Visualisations",
    "text": "Shiny Applications on Networks and Visualisations\n\n\nInputsOutputs\n\n\nThe Shiny app will include some of these parts.\n\nKnowledge graph\nAs the entire network is very large, containing 1,159 nodes and 3,226 edges, it is not suitable to visualize the entire network. Hence, we will plot with subgraphs and other visualisations.\n\n\nReference Node\nFor Nadia’s ego network, we require a reference node (Nadia).\n\n\nNetwork depth\nIn relation to the reference node, this serves to narrow down the network to view. The depth dictates how far from the reference node to network. As Nadia’s networks are at distance 1 or distance 2, we will add an option to toggle whether to render the full network or use the option to render by distance to the reference node.\n\n\n\n\nPlot area\nShows the network or visualisation plot. It will be interactive to enable closer inspection of network or visual elements.\n\n\n\n\nThese are some prototypes of the webpage and shiny application that we are planning to build for the project. The whole concept of this storyboard is mainly to allow the user to utilise interactive visualisations such as timeseries slides, clickable components, or hovers to get to the bottom of the activites brewing at Oceanus such as the Nemo Reef Operation. Hence, enhancing the whole user experience as they follow us along on uncovering the story."
  },
  {
    "objectID": "meeting_minutes.html",
    "href": "meeting_minutes.html",
    "title": "🌊 Meeting Minutes 🪸",
    "section": "",
    "text": "Date: 15/05/2025 \nTime: 7:30 - 8:00 PM\nIn Attendance: Li Jianyi, Yang Lu \nAgenda Items \n\nDiscussion on project topic \n\n\n\nAction items \n\nAgenda Item 1: Discussion on project topic \n\nPrior to the meeting, the team read the different challenges from VAST Challenge 2025 to select our respective preferences.  \n\n\n\nThe team disagreed to do the challenge as Yang Lu prefers MC2, while Li JianYi prefers MC3. \n\n\n\nThe team agreed on MC3 as we thought that through the challenge, we could utilise what we have learned in class and add more insights from our own current knowledge bank. \n\n\n\nThe team also informed Audrey on the team’s choice of MC3 as she mentioned she was fine with any topic since she was on medical leave. \n\nAction Items \n\nAll members will revisit the MC3 document to identify any gaps in understanding the knowledge graph’s structure and content. \n\n\n\n\nDate: 24/05/2025 \nTime: 3.45 - 4:15 PM \nIn Attendance: Li Jianyi, Yang Lu, Audrey \nAgenda Items \n\nSharing our work progress for MC3 \n\n\n\nDivision of tasks for Project Proposal \n\nAgenda Item 1: Sharing our work progress \n\nYang Lu is completing Question 1. Audrey is completing Questions 2 and 4.  \n\n\n\nJianyi will work on Question 3 and attempt other Questions if he has the time.  \n\nAgenda Item 2: Division of tasks for the project. \n\nThe team agreed to complete their assigned questions and attempt to complete other questions as much as possible if they have the time. \n\n\n\nThe team will refer to the project requirements and seniors’ work for references.\n\n\n\n\nDate: 02/06/2025 \nTime: 8.00 - 8:30 PM \nIn Attendance: Li Jianyi, Yang Lu, Audrey \nAgenda Items \n\nDivision of tasks for the project. \n\n\n\nAction items \n\nAgenda Item 1: Division of tasks for Project \n\nWe decided to focus on the most urgent component, which was the project proposal due on 8 June 2025.  \n\n\n\nJianyi will cover the Shiny and Netlify setup. \n\n\n\nYang Lu and Audrey will cover the Meeting Minutes and Project Proposal. \n\nAgenda Item 2: Action Items \n\nJianyi will help the team to push the Project Proposal to GitHub after Yang Lu and Audrey finish the Meeting Minutes and Project Proposal. \n\n\n\n\nDate: 07/06/2025 \nTime: 2.45 - 4:35 PM \nIn Attendance: Li Jianyi, Yang Lu, Audrey \nAgenda Items\n\nUI storyboard template and format\nThe distinction between Take-home Exercise 3 and the group project deliverable\nGitHub branching & collaboration workflow\n\nAgenda Item 1: UI Storyboard Template & Format\nTemplate Style\n\nAdopt a clean “dark-blue” or similar professional colour palette to be consistent with the theme of the project.\nUse consistent title headers, footers, and navigation bar mock-ups.\nPrint-screen of each implemented UI page\nCapture one overall shot of each primary view in the app, such as the homepage, the detail page, and the filter/control panel, so the storyboard illustrates the full user journey.\n\nAgenda Item 2: Distinction Group Project Website (Covert Reef)\n\nStatic homepage summarizing group methodology, team introduction and proposal.\nMay include embedded visuals, but not required to be Shiny.\nShared Netlify site under group account\nGitHub repo link for group deliverable (proposal, poster, minutes).\n\n\n\n\nDate: 23/06/2025 \nTime: 8.00PM - 9:30 PM \nIn Attendance: Li Jianyi, Yang Lu, Audrey \nAgenda Items\n\nHarmonization of data variables and nomenclature\nWebsite architecture and content framework\nWork distribution and consolidation approach\nInteractive vs static visualization deployment strategy\n\nAgenda Item 1: Harmonization of data variables and nomenclature\n\nIssue Identified: Inconsistent variable naming across individual team contributions creating merge conflicts\n\n\n\nResolution: Establish unified naming standards for all data objects and variables prior to code integration\n\n\n\nImplementation: Conduct comprehensive review to synchronize nomenclature across all team member submissions\n\nAgenda Item 2: Website architecture and content framework\n\nData Preparation Section: Decided to create a unified data preparation section combining all team members’ preprocessing work\nMethodology vs Findings: Clarified that methodology should cover overall approach, while findings will contain question-specific analyses\nContent Strategy:\n\nCopy and paste shared components (packages, introduction, data preparation)\nCombine individual question analyses under findings section\nMaintain consistent formatting across all sections\n\n\nAgenda Item 3: Work distribution and consolidation approach\nAnalysis 1: Primary implementation using Yang Lu’s temporal heat map visualization, supplemented by Audrey’s community structure analysis\nAnalysis 2:\n\nComponent A: Deploy Audrey’s community detection visualizations (reference sections 7.5.8 through 7.5.11)\nComponent B: Incorporate Li Jianyi’s network metrics including betweenness centrality calculations\nIntegration: Merge Audrey’s visual community mapping with Jianyi’s quantitative connectivity analysis (degree and betweenness centrality measures)\n\nAnalysis 3: Synthesize findings from Analyses 2A&B with 3A investigation, utilizing Audrey’s Interactive Alluvial Diagrams as analytical foundation while ensuring coherence across related questions\nAnalysis 4: Maintain existing individual response with team validation\nAgenda Item 4: Interactive vs static visualization deployment strategy\n\nTechnical Constraint: Shiny applications offer superior user interaction but lack direct Netlify compatibility\n\n\n\nHybrid Approach:\n\nPreserve Shiny implementations for enhanced demonstration capabilities\nDevelop static alternatives optimized for Netlify integration\n\n\n\n\nDevelopment Priority: Emphasize functional delivery over visual sophistication for web deployment"
  },
  {
    "objectID": "meeting_minutes.html#project-meeting-1",
    "href": "meeting_minutes.html#project-meeting-1",
    "title": "🌊 Meeting Minutes 🪸",
    "section": "",
    "text": "Date: 15/05/2025 \nTime: 7:30 - 8:00 PM\nIn Attendance: Li Jianyi, Yang Lu \nAgenda Items \n\nDiscussion on project topic \n\n\n\nAction items \n\nAgenda Item 1: Discussion on project topic \n\nPrior to the meeting, the team read the different challenges from VAST Challenge 2025 to select our respective preferences.  \n\n\n\nThe team disagreed to do the challenge as Yang Lu prefers MC2, while Li JianYi prefers MC3. \n\n\n\nThe team agreed on MC3 as we thought that through the challenge, we could utilise what we have learned in class and add more insights from our own current knowledge bank. \n\n\n\nThe team also informed Audrey on the team’s choice of MC3 as she mentioned she was fine with any topic since she was on medical leave. \n\nAction Items \n\nAll members will revisit the MC3 document to identify any gaps in understanding the knowledge graph’s structure and content."
  },
  {
    "objectID": "meeting_minutes.html#project-meeting-2",
    "href": "meeting_minutes.html#project-meeting-2",
    "title": "🌊 Meeting Minutes 🪸",
    "section": "",
    "text": "Date: 24/05/2025 \nTime: 3.45 - 4:15 PM \nIn Attendance: Li Jianyi, Yang Lu, Audrey \nAgenda Items \n\nSharing our work progress for MC3 \n\n\n\nDivision of tasks for Project Proposal \n\nAgenda Item 1: Sharing our work progress \n\nYang Lu is completing Question 1. Audrey is completing Questions 2 and 4.  \n\n\n\nJianyi will work on Question 3 and attempt other Questions if he has the time.  \n\nAgenda Item 2: Division of tasks for the project. \n\nThe team agreed to complete their assigned questions and attempt to complete other questions as much as possible if they have the time. \n\n\n\nThe team will refer to the project requirements and seniors’ work for references."
  },
  {
    "objectID": "meeting_minutes.html#project-meeting-3",
    "href": "meeting_minutes.html#project-meeting-3",
    "title": "🌊 Meeting Minutes 🪸",
    "section": "",
    "text": "Date: 02/06/2025 \nTime: 8.00 - 8:30 PM \nIn Attendance: Li Jianyi, Yang Lu, Audrey \nAgenda Items \n\nDivision of tasks for the project. \n\n\n\nAction items \n\nAgenda Item 1: Division of tasks for Project \n\nWe decided to focus on the most urgent component, which was the project proposal due on 8 June 2025.  \n\n\n\nJianyi will cover the Shiny and Netlify setup. \n\n\n\nYang Lu and Audrey will cover the Meeting Minutes and Project Proposal. \n\nAgenda Item 2: Action Items \n\nJianyi will help the team to push the Project Proposal to GitHub after Yang Lu and Audrey finish the Meeting Minutes and Project Proposal."
  },
  {
    "objectID": "meeting_minutes.html#project-meeting-4",
    "href": "meeting_minutes.html#project-meeting-4",
    "title": "🌊 Meeting Minutes 🪸",
    "section": "",
    "text": "Date: 07/06/2025 \nTime: 2.45 - 4:35 PM \nIn Attendance: Li Jianyi, Yang Lu, Audrey \nAgenda Items\n\nUI storyboard template and format\nThe distinction between Take-home Exercise 3 and the group project deliverable\nGitHub branching & collaboration workflow\n\nAgenda Item 1: UI Storyboard Template & Format\nTemplate Style\n\nAdopt a clean “dark-blue” or similar professional colour palette to be consistent with the theme of the project.\nUse consistent title headers, footers, and navigation bar mock-ups.\nPrint-screen of each implemented UI page\nCapture one overall shot of each primary view in the app, such as the homepage, the detail page, and the filter/control panel, so the storyboard illustrates the full user journey.\n\nAgenda Item 2: Distinction Group Project Website (Covert Reef)\n\nStatic homepage summarizing group methodology, team introduction and proposal.\nMay include embedded visuals, but not required to be Shiny.\nShared Netlify site under group account\nGitHub repo link for group deliverable (proposal, poster, minutes)."
  },
  {
    "objectID": "meeting_minutes.html#project-meeting-5",
    "href": "meeting_minutes.html#project-meeting-5",
    "title": "🌊 Meeting Minutes 🪸",
    "section": "",
    "text": "Date: 23/06/2025 \nTime: 8.00PM - 9:30 PM \nIn Attendance: Li Jianyi, Yang Lu, Audrey \nAgenda Items\n\nHarmonization of data variables and nomenclature\nWebsite architecture and content framework\nWork distribution and consolidation approach\nInteractive vs static visualization deployment strategy\n\nAgenda Item 1: Harmonization of data variables and nomenclature\n\nIssue Identified: Inconsistent variable naming across individual team contributions creating merge conflicts\n\n\n\nResolution: Establish unified naming standards for all data objects and variables prior to code integration\n\n\n\nImplementation: Conduct comprehensive review to synchronize nomenclature across all team member submissions\n\nAgenda Item 2: Website architecture and content framework\n\nData Preparation Section: Decided to create a unified data preparation section combining all team members’ preprocessing work\nMethodology vs Findings: Clarified that methodology should cover overall approach, while findings will contain question-specific analyses\nContent Strategy:\n\nCopy and paste shared components (packages, introduction, data preparation)\nCombine individual question analyses under findings section\nMaintain consistent formatting across all sections\n\n\nAgenda Item 3: Work distribution and consolidation approach\nAnalysis 1: Primary implementation using Yang Lu’s temporal heat map visualization, supplemented by Audrey’s community structure analysis\nAnalysis 2:\n\nComponent A: Deploy Audrey’s community detection visualizations (reference sections 7.5.8 through 7.5.11)\nComponent B: Incorporate Li Jianyi’s network metrics including betweenness centrality calculations\nIntegration: Merge Audrey’s visual community mapping with Jianyi’s quantitative connectivity analysis (degree and betweenness centrality measures)\n\nAnalysis 3: Synthesize findings from Analyses 2A&B with 3A investigation, utilizing Audrey’s Interactive Alluvial Diagrams as analytical foundation while ensuring coherence across related questions\nAnalysis 4: Maintain existing individual response with team validation\nAgenda Item 4: Interactive vs static visualization deployment strategy\n\nTechnical Constraint: Shiny applications offer superior user interaction but lack direct Netlify compatibility\n\n\n\nHybrid Approach:\n\nPreserve Shiny implementations for enhanced demonstration capabilities\nDevelop static alternatives optimized for Netlify integration\n\n\n\n\nDevelopment Priority: Emphasize functional delivery over visual sophistication for web deployment"
  },
  {
    "objectID": "tasks.html",
    "href": "tasks.html",
    "title": "🌊 Visual Analysis Finding 🪸",
    "section": "",
    "text": "Show the code\nlibrary(tidyverse)    \nlibrary(RColorBrewer) \nlibrary(circlize)     \nlibrary(stringr)      \n# --- Step 1: Build communication matrix ---\nsent_df &lt;- other_communications_df %&gt;%\n  filter(communication_type == \"sent\") %&gt;%\n  count(sender_name, recipient_name, name = \"sent\")\n\nreceived_df &lt;- other_communications_df %&gt;%\n  filter(communication_type == \"received\") %&gt;%\n  count(sender_name = recipient_name, recipient_name = sender_name, name = \"received\")\n\ncombined_df &lt;- full_join(sent_df, received_df, by = c(\"sender_name\", \"recipient_name\")) %&gt;%\n  mutate(across(c(sent, received), ~replace_na(., 0)),\n         total = sent + received)\n\ncomm_matrix &lt;- xtabs(total ~ sender_name + recipient_name, data = combined_df)\n\n# --- Step 2: Assign color per entity sub-type ---\ntype_lookup &lt;- other_communications_df %&gt;%\n  select(name = sender_name, type = sender_sub_type) %&gt;%\n  bind_rows(other_communications_df %&gt;% select(name = recipient_name, type = recipient_sub_type)) %&gt;%\n  distinct(name, .keep_all = TRUE)\n\n# Define pastel Set2 colors for each type\ntype_colors_palette &lt;- brewer.pal(n = 4, name = \"Set2\")\nnames(type_colors_palette) &lt;- c(\"Person\", \"Organization\", \"Vessel\", \"Location\")\n\n# Map to nodes in the matrix\ngrid_colors &lt;- type_colors_palette[type_lookup$type]\nnames(grid_colors) &lt;- type_lookup$name\ngrid_colors &lt;- grid_colors[rownames(comm_matrix)]\n\n# --- Step 3: Plot chord diagram ---\ncircos.clear()\npar(mar = c(4, 2, 8, 10))  # bottom, left, top, right\n\nchordDiagram(\n  comm_matrix,\n  grid.col = grid_colors,\n  transparency = 0.25,\n  annotationTrack = \"grid\",\n  preAllocateTracks = list(track.height = 0.1)\n)\n\n# Add readable sector names\ncircos.trackPlotRegion(\n  track.index = 1,\n  panel.fun = function(x, y) {\n    name &lt;- get.cell.meta.data(\"sector.index\")\n    circos.text(\n      x = mean(get.cell.meta.data(\"xlim\")),\n      y = 0,\n      labels = str_wrap(name, 10),\n      facing = \"clockwise\",\n      niceFacing = TRUE,\n      adj = c(0, 0.5),\n      cex = 0.6\n    )\n  },\n  bg.border = NA\n)\n\n# --- Step 4: Title, subtitle ---\ntitle(\n  main = \"Chord Diagram of Communication Flows\",\n  cex.main = 1.6,\n  font.main = 2,\n  line = 5\n)\nmtext(\"Each ribbon shows volume of sent + received messages\", side = 3, line = 3, cex = 1, col = \"gray30\")\nmtext(\"Note. Group subtype is excluded from this diagram\", side = 1, line = 3, cex = 0.8, col = \"gray40\")\n\n# --- Step 5: Custom Legend ---\nlegend_items &lt;- names(type_colors_palette)\nlegend(\n  x = 1.1, y = 0.85, legend = legend_items,\n  fill = type_colors_palette,\n  border = \"gray30\",\n  bty = \"n\",\n  cex = 0.7,\n  pt.cex = 0.7,\n  title = \"Entity Sub-Type\" \n\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFindings\n\n\n\nThe thickness of each ribbon (chord) represents the magnitude of the relationship. A thicker ribbon represents more frequent communications (sent + received) between a sender and recipient.\nHere, we have an overview of paired communicators who have higher frequencies. We also can see the links between communicators. These are the entities who communicated frequently with others that we might want to focus on:\n\nPerson: The Intern, The Lookout, Clepper Jensen, Davis, Miranda Jordan, Mrs. Money.\nOrganization: Oceanus City Council, Green Guardian\nVessel: Reef Guardian, Neptune, Mako, Remora\nLocation: Himark Habor\nGroup: N/A\n\n\n\n\n\n\nHere, the interactive chord diagram showed the correspondences among communities at every two hour intervals.\n\n\nShow the code\nlibrary(circlize)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(RColorBrewer)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(htmltools) # Essential for building the HTML structure\nlibrary(jsonlite) # For passing R data to JavaScript safely\n\n# --- 1. Data Preprocessing and Setup ---\n\n# Bin by 2-hour interval\nother_communications_df &lt;- other_communications_df %&gt;%\n  mutate(timestamp = as.POSIXct(timestamp)) %&gt;% # Ensure timestamp is POSIXct\n  mutate(timestamp_2hr = floor_date(timestamp, unit = \"2 hours\"))\n\n# Get all unique 2-hour time bins for the slider\nall_times &lt;- sort(unique(other_communications_df$timestamp_2hr))\n\n# Define output directory for image frames\noutput_dir &lt;- \"chord_frames\"\ndir.create(output_dir, showWarnings = FALSE) # Create the directory if it doesn't exist\n\n# Community name mapping (ensure this matches  'community_df' structure)\ncommunity_name_map &lt;- c(\n  \"1\" = \"Conservationist Group\",\n  \"2\" = \"Sailor Shift\",\n  \"3\" = \"Maritime\",\n  \"4\" = \"Suspicious Characters\",\n  \"5\" = \"Sam & Kelly\",\n  \"6\" = \"Hacklee Herald\"\n)\n\n\n# Assuming community_df has a 'community' column that's numeric/factor\nif (exists(\"community_df\") && \"community\" %in% names(community_df)) {\n  num_unique_communities &lt;- length(unique(community_df$community))\n  base_colors &lt;- brewer.pal(max(3, num_unique_communities), \"Set2\") # Use Set2 for pastel\n  community_colors &lt;- setNames(\n    base_colors[1:num_unique_communities], # Slice to exactly the number needed\n    as.character(sort(unique(community_df$community)))\n  )\n} else {\n  # Fallback if community_df is not defined or missing 'community' column\n  message(\"Warning: 'community_df' or 'community' column not found. Using default colors.\")\n  community_colors &lt;- c(\n    \"1\" = \"#66C2A5\", \"2\" = \"#FC8D62\", \"3\" = \"#8DA0CB\", \"4\" = \"#E78AC3\",\n    \"5\" = \"#A6D854\", \"6\" = \"#FFD92F\", \"7\" = \"#E5C494\", \"8\" = \"#B3B3B3\"\n  )\n}\n\n\n# --- 2. Generate and Save Chord Diagrams as PNGs ---\n\n# Loop through each time bin, create a plot, and save it\nfor (i in seq_along(all_times)) {\n  selected_time &lt;- all_times[i]\n  end_time &lt;- selected_time + hours(2)\n\n  filtered_df &lt;- other_communications_df %&gt;%\n    filter(timestamp_2hr == selected_time)\n\n  # Prepare data for the chord diagram matrix\n  sent_df &lt;- filtered_df %&gt;%\n    filter(communication_type == \"sent\") %&gt;%\n    count(sender_name, recipient_name, name = \"sent\")\n\n  received_df &lt;- filtered_df %&gt;%\n    filter(communication_type == \"received\") %&gt;%\n    count(sender_name = recipient_name, recipient_name = sender_name, name = \"received\")\n\n  combined_df &lt;- full_join(sent_df, received_df, by = c(\"sender_name\", \"recipient_name\")) %&gt;%\n    mutate(across(c(sent, received), ~replace_na(., 0)),\n           total = sent + received)\n\n  # Skip this iteration if no data for the current time slice\n  if (nrow(combined_df) == 0 || sum(combined_df$total) == 0) {\n    message(paste(\"No communications for time:\", selected_time, \". Skipping frame.\"))\n\n    next\n  }\n\n  comm_matrix &lt;- xtabs(total ~ sender_name + recipient_name, data = combined_df)\n\n  # Ensure sector_names from comm_matrix exist in community_df for color mapping\n  sector_names &lt;- union(rownames(comm_matrix), colnames(comm_matrix))\n  \n  # Filter community_df to only relevant sectors and ensure distinct entries\n  sector_community_df &lt;- community_df %&gt;%\n    filter(name %in% sector_names) %&gt;%\n    distinct(name, .keep_all = TRUE) %&gt;%\n    arrange(match(name, sector_names))\n\n  # Map community colors to sector names based on 'community' column\n  grid_colors_current_frame &lt;- setNames(\n    community_colors[as.character(sector_community_df$community)],\n    sector_community_df$name\n  )\n  # Ensure only colors for actual sectors in the matrix are used\n  grid_colors_current_frame &lt;- grid_colors_current_frame[names(grid_colors_current_frame) %in% sector_names]\n\n\n  # Open PNG device for saving the plot\n  png(sprintf(\"%s/frame_%03d.png\", output_dir, i), width = 800, height = 800)\n  \n  # Clear existing circlize plot before drawing new one\n  circos.clear()\n  par(mar = c(6, 2, 10, 6)) # Adjust margins as needed for title and labels\n\n  # Draw the chord diagram\n  chordDiagram(\n    comm_matrix,\n    grid.col = grid_colors_current_frame,\n    transparency = 0.25,\n    annotationTrack = \"grid\",\n    preAllocateTracks = list(track.height = 0.1)\n  )\n\n  # Add labels to the sectors\n  circos.trackPlotRegion(\n    track.index = 1,\n    panel.fun = function(x, y) {\n      name &lt;- get.cell.meta.data(\"sector.index\")\n      wrapped_name &lt;- str_wrap(name, width = 12)\n      circos.text(\n        x = mean(get.cell.meta.data(\"xlim\")),\n        y = 0,\n        labels = wrapped_name,\n        facing = \"clockwise\",\n        niceFacing = TRUE,\n        adj = c(0, 0.5),\n        cex = 0.8\n      )\n    },\n    bg.border = NA\n  )\n\n  # Add a main title to the plot\n  title(\n    main = paste(\"Communication Flows\\n\", format(selected_time, \"%d %b %Y (%H:%M\"), \"to\", format(end_time, \"%H:%M)\")),\n    cex.main = 1.2,\n    font.main = 1,\n    line = 6\n  )\n  dev.off() # CRITICAL: Close the PNG device to save the file\n}\n\n# --- 3. Build the HTML Viewer with Embedded Images and JavaScript ---\n\n# Generate HTML &lt;img&gt; tags for each saved frame\n# Filter out any frames that might have been skipped if 'next' was used\n# Check which frame files actually exist\nexisting_frames &lt;- list.files(output_dir, pattern = \"^frame_\\\\d{3}\\\\.png$\", full.names = TRUE)\n# Extract the numeric index from the filename to match with all_times\nframe_indices &lt;- as.numeric(gsub(\"frame_(\\\\d{3})\\\\.png\", \"\\\\1\", basename(existing_frames)))\n\n# Only create image tags for the frames that were successfully generated\nimage_tags &lt;- lapply(seq_along(existing_frames), function(idx) {\n  # The original 'i' (loop index) corresponds to the 'frame_indices'\n  original_time_idx &lt;- frame_indices[idx]\n  tags$img(src = existing_frames[idx], # Use the full path here\n           style = if (idx == 1) \"display:block;\" else \"display:none;\", # Show first frame by default\n           class = \"chord-frame\",\n           alt = paste(\"Chord diagram for time slice\", format(all_times[original_time_idx], \"%d %b %Y %H:%M\")))\n})\n\n\n# JavaScript function to update which image frame is visible\n# We need to map the slider value (0 to num_frames-1) to the correct time index\n# because some frames might be skipped, causing gaps in numerical sequence.\njs_script &lt;- HTML(sprintf(\"\n&lt;script&gt;\n  // Ensure the allTimes array correctly maps to the generated frames\n  const originalAllTimes = %s; // This is the full list of all_times\n  const generatedFrameIndices = %s; // This indicates which original_time_idx corresponds to a generated frame\n\n  function updateFrame(sliderIndex) {\n    const frames = document.querySelectorAll('.chord-frame');\n    frames.forEach((el, i) =&gt; {\n      // frames[i] corresponds to existing_frames[i] from R\n      // sliderIndex is 0-based for the slider\n      el.style.display = (i === sliderIndex) ? 'block' : 'none';\n    });\n\n    // Update the time display text based on the current frame's original time\n    const timeDisplay = document.getElementById('current-time-display');\n    if (timeDisplay && sliderIndex &lt; generatedFrameIndices.length) {\n        // Get the original time index for the currently displayed frame\n        const actualTimeIndex = generatedFrameIndices[sliderIndex] - 1; // Convert 1-based to 0-based for originalAllTimes\n        \n        if (actualTimeIndex &gt;= 0 && actualTimeIndex &lt; originalAllTimes.length) {\n            const selectedTime = new Date(originalAllTimes[actualTimeIndex]);\n            const endTime = new Date(selectedTime.getTime() + 2 * 60 * 60 * 1000); // Add 2 hours in milliseconds\n\n            // Format dates and times for display\n            const formatDate = (date) =&gt; date.toLocaleDateString('en-US', { day: '2-digit', month: 'short', year: 'numeric' });\n            const formatTime = (date) =&gt; date.toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit', hour12: false });\n            \n            timeDisplay.innerHTML = `Day: ${formatDate(selectedTime)} | Time: ${formatTime(selectedTime)} to ${formatTime(endTime)}`;\n        } else {\n            timeDisplay.innerHTML = 'No data for this time slice.';\n        }\n    }\n  }\n\n  // Initialize the display on page load\n  document.addEventListener('DOMContentLoaded', () =&gt; {\n    const slider = document.getElementById('frameSlider');\n    if (slider) {\n        updateFrame(parseInt(slider.value)); // Set initial frame based on slider's default value\n    }\n  });\n&lt;/script&gt;\n\", jsonlite::toJSON(as.character(all_times)), jsonlite::toJSON(frame_indices))) # Pass all_times and frame_indices to JS\n\n\n# --- 4. Display the HTML content directly in the Quarto document ---\n# This is the key line to make Quarto embed the interactive viewer.\nbrowsable(\n  tagList(\n    js_script, # The JavaScript for interactivity\n    tags$head(\n      tags$style(HTML(\"\n        /* Basic styling for the image frames and slider container */\n        .chord-frame { width: 100%; max-width: 800px; height: auto; margin: auto; display: block; }\n        #slider-container { text-align: center; margin: 20px auto; max-width: 800px; }\n        .chord-title { text-align: center; font-size: 1.5em; margin-bottom: 15px; font-weight: bold; }\n        #frameSlider { width: 80%; max-width: 700px; margin: 10px auto; display: block; }\n        #current-time-display { font-weight: bold; margin-top: 10px; }\n      \"))\n    ), # Close tags$head\n\n    tags$body( \n      tags$div(class = \"chord-title\", \"Interactive Communication Flows Over Time\"),\n      tags$div(id = \"slider-container\",\n          tags$input(type = \"range\", min = \"0\", max = length(existing_frames) - 1, value = 0,\n                     id = \"frameSlider\", oninput = \"updateFrame(parseInt(this.value))\"),\n          tags$p(id = \"current-time-display\", style = \"font-weight:bold; margin-top: 10px;\"),\n          tags$p(\"Use the slider to view communication over time\")\n      ),\n      tags$div(id = \"chord-images-container\", image_tags) # Container for all image frames\n    )\n  )\n)\n\n\n\n\n\n\nInteractive Communication Flows Over Time\n\n\n\nUse the slider to view communication over time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.2 Findings\n\n\n\nWe noticed some cross community direct and indirect communication occured mainly among influential nodes, suggesting collaboration. These are some sample linkages with arrows regardless of sent or received:\n\n\n\n\n\n\n\nCommunity X\nNode Linkages (Community X -&gt; Community X -&gt; Community Y)\n\n\n\n\nSuspicious Characters\nMrs. Money -&gt; Intern -&gt; The Lookout\nLiam -&gt; Paackland Harbor -&gt; The Middleman\nGlitters Team -&gt; Boss -&gt; Mako\nGlitters Team -&gt; Samantha Blake -&gt; Sailor Shifts Team\n\n\nSailor Shift\nNeptune -&gt; Elise -&gt; Mako\nNeptune -&gt; Davis -&gt; Mako\nRemora -&gt; Neptune -&gt; Boss\nRodriguez -&gt; Remora -&gt; Mako\nRemora -&gt; Small Fry -&gt; Mako\nDavis -&gt; Remora -&gt; Paackland Harbor\nV. Miesel Shipping -&gt; Neptune -&gt; Mako\n\n\nSam & Kelly\nKelly -&gt; Sam - &gt; The Lookout\n\n\nMaritime\nMako -&gt; Himark Harbor -&gt; Oceanus City Council\n\n\nHacklee Herald\nN/A (Only Direct Community X to X communications)\n\n\nConservationist Group\nReef Guardian -&gt; Oceanus City Council -&gt; Nadia\nReef Guardian -&gt; Paackland Harbor -&gt; Mako\nOceanus City Council -&gt; Liam -&gt; Nadia\n\n\n\n\n\nWe also noticed that at times, certain individuals sent messages but there were no response back. This could possibly be due to the pseudonyms being used to send or reply to the same content. For instance, there was a message from Davis to Rodriguez on 14 Oct around 1200-1400 but there was no response by Rodriguez. By looking at the content field, we then found out that he was Small Fry due to the responses he provided to Davis which was originally addressed to Rodriguez.\n\n\n\n\nHeatmap of CorrespondencesThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Step 1: Count interactions\nadj_df &lt;- other_communications_df %&gt;%\n  count(sender_name, recipient_name, name = \"count\")\n\n# Step 2: Compute total sent and received counts\nsender_order &lt;- adj_df %&gt;%\n  group_by(sender_name) %&gt;%\n  summarise(total_sent = sum(count)) %&gt;%\n  arrange(desc(total_sent)) %&gt;%\n  pull(sender_name)\n\nrecipient_order &lt;- adj_df %&gt;%\n  group_by(recipient_name) %&gt;%\n  summarise(total_received = sum(count)) %&gt;%\n  arrange(desc(total_received)) %&gt;%\n  pull(recipient_name)\n\n# Step 3: Reorder factor levels\nadj_df &lt;- adj_df %&gt;%\n  mutate(\n    sender_name = factor(sender_name, levels = sender_order),\n    recipient_name = factor(recipient_name, levels = recipient_order)\n  )\n\n# Step 4: Plot heatmap\nggplot(adj_df, aes(x = recipient_name, y = sender_name, fill = count)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"white\", high = \"navyblue\") +\n  labs(\n    title = \"Sender-Recipient Communication Heatmap\",\n    subtitle = \"Top communicators sorted to bottom-left\",\n    x = \"Recipient\",\n    y = \"Sender\",\n    fill = \"Messages\"\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 12, face = \"bold\"),\n    plot.subtitle = element_text(size = 10),\n    panel.grid = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n1.3 Findings\n\n\n\nAfter extraction of the entities who communicated frequently (from the Static Chord Diagram), we tabled who they communicated with by using the heatmap. E.g. Name1 communicated with Name2.\n\n\n\n\n\n\n\n\nName 1 Subtype\nName1\nName2\n\n\n\n\nPerson\nThe Intern\nThe Lookout, Mrs. Money\n\n\nPerson\nClepper Jensen\nMiranda Jordan\n\n\nPerson\nDavis\nNeptune\n\n\nPerson\nMrs. Money\nThe Intern, The Middleman, Boss\n\n\nVessel\nMako\nRemora, Green Guardians, Oceanus City Council, Neptune, Reef Guardians, Himark Harbor, Davis, Sentinel, Paackland Habor, Samantha Blake, Serenity, Osprey\n\n\nVessel\nRemora\nMako, Neptune, Himark Habor, Davis, Paackland Harbor, V. Miesel Shipping, Marlin, Small Fry\n\n\nVessel\nNeptune\nMako, Himark Habor, Remora, Mrs Money, V. Miesel Shipping, Nadia, Serenity\n\n\nVessel\nReef Guardian\nGreen Guardians, Oceanus City Council, Mako, Paackland Harbor, EcoVigil, Serenity, Defender\n\n\nOrganization\nGreen Guardian\nGreen Guardians, Oceanus City Council, The Lookout, Sentinel, Horizon\n\n\nOrganization\nOceanus City Council\nGreen Guardians, Reef Guardians, Himark Harbor, Sentinel, Paackland Harbor, Liam Thorne, Samantha Blake, Haacklee Harbor\n\n\nLocation\nHimark Habor\nOceanus City Council, Mako, Serenity, Marlin\n\n\n\n\n\n\n\n\n\nHeatmap of date and hoursThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Load data\nMC3_graph &lt;- fromJSON(\"data/MC3_graph.json\")\nnodes_tbl  &lt;- as_tibble(MC3_graph$nodes)\nedges_tbl  &lt;- as_tibble(MC3_graph$edges)\n\n# Extract only the communication events\ncomm_nodes &lt;- nodes_tbl %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp)\n\n# Pull out who sent and who received each message\nsent_edges &lt;- edges_tbl %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(sender = source, event_id = target)\n\nrecv_edges &lt;- edges_tbl %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = source, receiver = target)\n\n#  Join everything together and parse the timestamp\nmsgs &lt;- sent_edges %&gt;%\n  inner_join(recv_edges, by = \"event_id\") %&gt;%\n  inner_join(comm_nodes, by = \"event_id\") %&gt;%\n  mutate(\n    ts   = ymd_hms(timestamp, tz = \"UTC\"),\n    date = as_date(ts),\n    hour = hour(ts)\n  )\n\n# Build a complete date×hour grid, filling in zeros where needed\nheatmap_data &lt;- msgs %&gt;%\n  count(date, hour) %&gt;%\n  complete(\n    date = seq(min(date), max(date), by = \"1 day\"),\n    hour = 0:23,\n    fill = list(n = 0)\n  )\n\n#Plot the heatmap\nggplot(heatmap_data, aes(x = hour, y = date, fill = n)) +\n  geom_tile(color = \"white\") +\n  scale_x_continuous(\n    breaks = 0:23,\n    expand = c(0, 0)\n  ) +\n  scale_y_date(\n    breaks      = seq(min(heatmap_data$date), max(heatmap_data$date), by = \"1 day\"),\n    date_labels = \"%b %d\",\n    expand      = c(0, 0)\n  ) +\n  scale_fill_distiller(\n    name    = \"Messages\",\n    palette = \"Spectral\",\n    direction = 1\n  ) +\n  labs(\n    title = \"Daily Communication Patterns\",\n    x     = \"Hour of Day\",\n    y     = \"Date\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(hjust = 0.5),\n    axis.text.y = element_text(size = 8),\n    panel.grid  = element_blank()\n  )\n\n\n\n\n\n\n\n\nCompare the communication patternThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmsgs &lt;- msgs %&gt;%\n  mutate(\n    week = if_else(date &lt;= min(date) + days(6), \"Week 1\", \"Week 2\")\n  )\n# Count and normalize within each week\nweek_patterns &lt;- msgs %&gt;%\n  count(week, hour) %&gt;%\n  group_by(week) %&gt;%\n  mutate(proportion = n / sum(n))\n\n\nhour_breaks &lt;- seq(min(week_patterns$hour), max(week_patterns$hour), by = 1)\nprop_breaks &lt;- seq(\n  0,\n  ceiling(max(week_patterns$proportion) * 100) / 100,\n  by = 0.02\n)\n\nggplot(week_patterns, aes(x = hour, y = proportion, color = week)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  scale_x_continuous(breaks = hour_breaks) +\n  scale_y_continuous(\n    breaks = prop_breaks,\n    labels = percent_format(accuracy = 1)\n  ) +\n  labs(\n    title = \"Hourly Communication Patterns: Week 1 vs Week 2\",\n    x     = \"Hour of Day\",\n    y     = \"Percent of Total Messages\"\n  ) +\n  theme_light(base_size = 12) +\n  theme(\n    plot.title      = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    legend.position = \"top\",\n    legend.title    = element_blank(),\n    panel.grid.major = element_line(color = \"grey80\"),\n    panel.grid.minor = element_line(color = \"grey90\"),\n    axis.text.x     = element_text(vjust = 0.5),\n    axis.text.y     = element_text(size = 8)\n  )\n\n\n\n\n\n\n\n\n\n\nFindings\n\n\n\nThe visualization of hourly communication patterns reveals that message activity in Oceanus follows a pronounced daily cycle, with distinct peaks and lows across both observed weeks.\nIn Week 1, communication is highly concentrated in the morning hours, particularly between 8 AM and 12 PM, where a majority of the messages are exchanged.\nBy contrast, Week 2 shows a broader distribution of communication throughout the day, with notable increases in afternoon and evening activity.\nThis shift suggests that while the first week’s communications were more focused and possibly related to regular planning or operational updates, the second week’s patterns reflect heightened activity or more dynamic coordination, potentially due to emergent events or increased urgency among entities."
  },
  {
    "objectID": "tasks.html#people-and-vessels",
    "href": "tasks.html#people-and-vessels",
    "title": "🌊 Visual Analysis Finding 🪸",
    "section": "2.2 People and Vessels",
    "text": "2.2 People and Vessels\n\n2.2.1 Filter by Vessel and Person only\n\nperson_vessel_df &lt;- other_communications_df %&gt;%\n  filter(\n    (sender_sub_type == \"Person\" & recipient_sub_type == \"Vessel\") |\n    (sender_sub_type == \"Vessel\" & recipient_sub_type == \"Person\") |\n    (sender_sub_type == \"Person\" & recipient_sub_type == \"Person\") |\n    (sender_sub_type == \"Vessel\" & recipient_sub_type == \"Vessel\")\n  )\n\n\n\n2.2.2 Plotted Timeline- People & Vessels\n\n\nShow the code\n# --- FACTORING and DATETIME CLEANING ---\nperson_vessel_df_for_plot &lt;- person_vessel_df %&gt;%\n  mutate(\n    timestamp = as.POSIXct(timestamp),\n    comm_date = as.Date(timestamp),\n    comm_time_of_day = hms::as_hms(format(timestamp, \"%H:%M:%S\")),\n    sender_sub_type = factor(sender_sub_type, levels = c(\"Person\", \"Vessel\")),\n    communicating_pair_sorted = paste(pmin(sender_name, recipient_name), pmax(sender_name, recipient_name), sep = \" & \")\n  )\n\n# --- WRAPPING CONTENT AND TOOLTIP ---\nplot_data1 &lt;- person_vessel_df_for_plot %&gt;%\n  mutate(\n    timestamp = as.POSIXct(timestamp),\n    date = as.Date(timestamp),\n    time = format(timestamp, \"%H:%M:%S\"),\n    wrapped_content = str_wrap(content, width = 50),\n    tooltip_text = paste0(\n      \"&lt;b&gt;Date:&lt;/b&gt; \", date, \"&lt;br&gt;\",\n      \"&lt;b&gt;Time:&lt;/b&gt; \", time, \"&lt;br&gt;\",\n      \"&lt;b&gt;From:&lt;/b&gt; \", sender_name, \"&lt;br&gt;\",\n      \"&lt;b&gt;To:&lt;/b&gt; \", recipient_name, \"&lt;br&gt;\",\n      \"&lt;b&gt;Event_id:&lt;/b&gt; \", event_id, \"&lt;br&gt;&lt;br&gt;\",\n      \"&lt;b&gt;Content:&lt;/b&gt;&lt;br&gt;\", wrapped_content\n    )\n  )\n\n# Plot\np &lt;-ggplot(plot_data1, aes(x = comm_date, y = comm_time_of_day)) +\n  geom_point(aes(\n    color = sender_id,\n    shape = sender_sub_type,\n    text = tooltip_text\n  ),show.legend = c(color = TRUE, shape = FALSE), \n  size = 2, alpha = 0.7) +\n  scale_shape_manual(values = c(\"Person\" = 16, \"Vessel\" = 17)) +\n  facet_wrap(~ sender_sub_type, ncol = 1, scales = \"fixed\") +\n  scale_y_time(\n    limits = hms::as_hms(c(\"08:00:00\", \"14:00:00\")),  # reversed to show time top-to-bottom\n    breaks = hms::as_hms(c(\"08:00:00\", \"09:00:00\", \"10:00:00\", \"11:00:00\", \"12:00:00\", \"13:00:00\", \"14:00:00\")),\n    labels = c(\"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\")\n)+\n  scale_x_date(\n  date_breaks = \"1 day\",\n  date_labels = \"%d %b\"\n)+\n  labs(\n    title = \"Communication Events Over Time (Sender's Perspective)\",\n    x = \"Date\",\n    y = \"Time of Day\",\n    color = \"Sender (subtype, name)\"\n  ) +\n  theme_grey() +\n  theme(\n    axis.text.y = element_text(size = 6),\n    axis.title.y = element_text(size = 7),\n    axis.ticks.y = element_line(),\n    axis.text.x = element_text(size = 6, angle = 45, hjust = 1),\n    axis.title.x = element_text(margin = margin(t = 8), size = 7),\n    panel.spacing = unit(0.5, \"lines\"),  # Applies to both x and y spacing\n    strip.text = element_text(size = 8, face = \"bold\"),\n    legend.position = \"bottom\",\n    legend.text = element_text(size = 6),\n    legend.title = element_blank()\n  )\n\n# --- Convert to interactive plot ---\nggplotly(p, tooltip = \"tooltip_text\")\n\n\n\n\n\n\n\n2.2.3 Findings on People/ Vessels:\n\n\n\n\n\n\nFindings\n\n\n\n\nCore logic:\n\nIf two names appear as sender and recipient in the same message, they cannot belong to the same person — i.e., they’re not aliases of each other.\nIf two names sent a message at the exact time, they cannot belong to the same person.\nFor instance, if Nadia sent a message to The Accountant, they would not be the same individual. If Nadia sent a message at 10am to The Accountant and The Lookout also sent a message at 10am to The Intern, Nadia and The Lookout cannot be the same person.\n\nSelect only The Accountant, Mrs. Money, Elise: We see close timings between Mrs. Money and Elise on 8 Oct, and 10 Oct. These were on the same topic. Elise then disappears from radar on 10 Oct. She reappears as The Accountant and Mrs. Money on 11 Oct on the same topic and remains only as The Accountant till 14 Oct.\nSelect only Liam and The Middleman: The Middleman disappeared on 7 Oct and appeared as Liam on 8 Oct. On 11 Oct Mrs. Money asked The Middleman if anything was found by conservation vessels. On the same day, Liam reappeared and replied Elise that nothing was found by them.\nSelect only The Boss and Nadia: The Boss disappeared on 5 Oct and reappeared as Nadia on 8 Oct. Likely the same person.\nSelect only Small Fry and Rodriguez: on 2 Oct Rodriguez corresponded with Remora and Mako on meeting at the slip #14. It happened again on 14 Oct as he took on dual roles and responded to the same message with different names. Likely the same person.\nSelect only The Lookout and Sam: on 7 Oct Sam asked Kelly to get information on who authorized the permit. 2 minutes later, The Lookout (Kelly) responded to The Intern (Sam), that it was signed by Jensen from City Council.\nSeawatch only appeared on 10 Oct but Horizon talked to Seawatch on 8 Oct. Therefore, some other entity is Seawatch before or during 8 Oct. Defender told Seawatch on 3 Oct at 8.39am that it increased its patrol and informed Seawatch to maintain vigilance. The Lookout (Seawatch) responded to Sentinel (Defender) at 8.41am that it acknowledged the need for vigilance.\n\n\n\n\n\n\nQuestion 2b)\n\n\n2.3 Centrality Measure- People & Vessels\n\n\n\n\n\n\n\n\n\n\nPageRank Centrality AlgorithmThe NetworkThe Code\n\n\n\n\n# A tibble: 10 × 5\n   name          pagerank degree betweenness closeness\n   &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 Mako            0.105      26      146.      0.0244\n 2 Reef Guardian   0.0741     19       57.2     0.0208\n 3 Neptune         0.0536     14       16.2     0.02  \n 4 Remora          0.0477     12        9.94    0.0182\n 5 Davis           0.0452     11       10.6     0.0182\n 6 Mrs. Money      0.0429     10       34.6     0.0192\n 7 Boss            0.0425     10       34.1     0.0185\n 8 Sentinel        0.0410     10       25.8     0.02  \n 9 Nadia Conti     0.0402     10       15.0     0.0185\n10 Horizon         0.0376      9       11.6     0.0192\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\n# --- STEP: Compute Centrality Measures ---\ng_pv &lt;- g_pv %&gt;%\n  mutate(\n    pagerank = centrality_pagerank(),\n    degree = centrality_degree(),\n    betweenness = centrality_betweenness(),\n    closeness = centrality_closeness()\n  )\n\n# Show top 10 nodes by PageRank\ng_pv %&gt;%\n  as_tibble() %&gt;%\n  select(name, pagerank, degree, betweenness, closeness) %&gt;%\n  arrange(desc(pagerank)) %&gt;%\n  head(10)\n\n# Visualize by Centrality\nggraph(g_pv, layout = \"fr\") +\n  geom_edge_link(alpha = 0.3) +\n  geom_node_point(aes(size = pagerank, color = as.factor(community)), alpha = 0.8) +\n  geom_node_text(aes(label = name), repel = TRUE, size = 3) +\n  theme_void() +\n  labs(title = \"Network with PageRank Centrality\",\n       size = \"PageRank\", color = \"Community\")\n\n\n\n\n\n\n\n\n\n\n2.3.1 Findings:\n\n\n\n\nThere were 5 closely associated groups. Community 5 (Clepper and Miranda) appeared to be segmented from the central group, due to the non-involvement from the nature of their investigative work.\nFrom the graph, we extracted the 8 influential nodes to focus on:\n\nCommunity 1: Mako\nCommunity 2: Neptune, Remora, Nadia, Davis\nCommunity 3: N/A as they were not very influential at global level\nCommunity 4: Mrs. Money, Boss, The Middleman\nCommunity 5: N/A as they were not very influential at global level\n\n\n\n\n\n\n2.4 Wordclouds- Bigrams\nWe focused on bigrams here to get more contextual data from two instead of one word.\n\nThe WordcloudsThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# 5b. Plot word clouds per community\nvalid_communities &lt;- unique(g_pv %&gt;% as_tibble() %&gt;% pull(community))\n\npar(mfrow = c(2, 3))  # Still allocate 6 slots, but you can adjust this\nfor (i in sort(valid_communities)) {\n  words &lt;- bigrams %&gt;% filter(community == i)\n  \n  if (nrow(words) &lt; 1) next\n  \n  suppressWarnings({\n    set.seed(432)  # Set seed for reproducibility\n    wordcloud(words = words$bigram,  # &lt;-- FIXED here\n              freq = words$n,\n              max.words = min(30, nrow(words)),\n              scale = c(3, 0.5),\n              colors = brewer.pal(8, \"Dark2\"),\n              random.order = FALSE)\n  })\n  mtext(paste(\"Community\", i), side = 3, line = 1, adj = 0.5, cex = 1.5, col = \"black\")\n}\n\n\n\n\n\n\n2.5 Circular barchart for Top Bigrams per Community\n\nThe Circular BarchartThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\n\nvalid_communities &lt;- g_pv %&gt;%\n  as_tibble() %&gt;%\n  distinct(community) %&gt;%\n  pull(community)\n\nbigrams &lt;- bigrams %&gt;% filter(community %in% valid_communities)\n\n# --- Configuration ---\nnum_top_bigrams_per_community &lt;- 8\nempty_bar_count &lt;- 2 # gaps btw comm.\n#excluded_community &lt;- 5 # too little in community 5\n\n# --- 1. Prepare the Combined Dataset ---\nall_communities_data &lt;- bigrams %&gt;%\n#  filter(community != excluded_community) %&gt;%\n  group_by(community) %&gt;%\n  arrange(desc(n)) %&gt;%\n  slice_head(n = num_top_bigrams_per_community) %&gt;%\n  ungroup()\n\nall_communities_data$community &lt;- as.factor(all_communities_data$community)\n\nto_add &lt;- data.frame(\n  bigram = NA,\n  n = NA,\n  community = rep(levels(all_communities_data$community), each = empty_bar_count)\n)\n\nplot_data &lt;- rbind(all_communities_data, to_add) %&gt;%\n  arrange(community)\n\nplot_data$id &lt;- seq_len(nrow(plot_data)) # Keep ID as numeric here\n\n# --- 2. Prepare Label Data ---\nlabel_data &lt;- plot_data\nnumber_of_bar &lt;- nrow(label_data)\nlabel_data$angle &lt;- 90 - 360 * (label_data$id - 0.5) / number_of_bar\nlabel_data$hjust &lt;- ifelse(label_data$angle &lt; -90, 1, 0)\nlabel_data$angle &lt;- ifelse(label_data$angle &lt; -90, label_data$angle + 180, label_data$angle)\n\n# --- 3. Prepare Data for Baselines (Community Dividers) ---\nbase_data &lt;- plot_data %&gt;%\n  group_by(community) %&gt;%\n  summarize(\n    start = min(id, na.rm = TRUE), # Keep as numeric\n    end = max(id, na.rm = TRUE) - empty_bar_count # Keep as numeric\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    title_position = mean(c(start, end))\n  ) %&gt;%\n  ungroup()\n\n# --- 4. Prepare Data for Grid Lines (Optional: Value Scales) ---\nmax_n_value &lt;- max(plot_data$n, na.rm = TRUE)\ngrid_lines_values &lt;- c(20, 40, 60, 80, 100)\ngrid_lines_values &lt;- grid_lines_values[grid_lines_values &lt;= max_n_value]\n\ngrid_segments_data &lt;- plot_data %&gt;%\n  group_by(community) %&gt;%\n  summarize(\n    start_id = min(id, na.rm = TRUE), # Keep as numeric\n    end_id = max(id, na.rm = TRUE) - empty_bar_count # Keep as numeric\n  )\n\ngrid_data_final &lt;- tibble()\nfor(val in grid_lines_values) {\n  temp_data &lt;- grid_segments_data %&gt;%\n    mutate(y_value = val)\n  grid_data_final &lt;- bind_rows(grid_data_final, temp_data)\n}\n\n# --- Data for grid line LABELS ---\ngrid_label_data &lt;- data.frame(\n  x_pos = max(plot_data$id, na.rm = TRUE) + 2, # Fixed x position outside the plot\n  y_pos = grid_lines_values,\n  label_text = as.character(grid_lines_values)\n)\n\n# --- 5. Make the Unified Plot ---\np &lt;- ggplot(plot_data, aes(x = id, y = n, fill = community)) + # &lt;--- x = id (numeric)\n  # Add background grid lines for value (e.g., 20, 40, 60, 80)\n  geom_segment(data = grid_data_final,\n               aes(x = start_id - 0.5, y = y_value, xend = end_id + 0.5, yend = y_value),\n               inherit.aes = FALSE,\n               color = \"grey\", alpha = 0.8, linewidth = 0.3) +\n\n  # Add text showing the value of each grid line at a fixed position\n  geom_text(data = grid_label_data,\n            aes(x = x_pos, y = y_pos, label = label_text),\n            inherit.aes = FALSE,\n            color = \"grey\", size = 3, angle = 0, fontface = \"bold\", hjust = 0) +\n\n  # Bars for the bigrams (main plot elements)\n  geom_bar(stat = \"identity\", alpha = 0.8, color = \"white\", linewidth = 0.1,\n           width = 1) + # &lt;--- Add width=1 to remove space between bars if id is numeric\n\n  # Set limits for the y-axis, providing space for labels\n  ylim(-max_n_value * 0.7, max_n_value * 1.2) +\n\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    axis.text = element_blank(),\n    axis.title = element_blank(),\n    panel.grid = element_blank(),\n    plot.margin = unit(c(1.5, 1.5, 1.5, 1.5), \"cm\") # Top, Right, Bottom, Left margins\n  ) +\n  coord_polar(start = 0) +\n\n  # Add bigram labels\n  geom_text(\n    data = label_data,\n    aes(x = id, y = n + 10, label = bigram, hjust = hjust), # &lt;--- x = id (numeric)\n    color = \"black\", fontface = \"bold\", alpha = 0.8, size = 2.8,\n    angle = label_data$angle, inherit.aes = FALSE\n  ) +\n\n  # Add base lines for each community segment\n  geom_segment(\n    data = base_data,\n    aes(x = start - 0.5, y = -10, xend = end + 0.5, yend = -10),\n    colour = \"black\", alpha = 0.8, linewidth = 0.6, inherit.aes = FALSE\n  ) +\n\n  # Add community group labels\n  geom_text(\n    data = base_data,\n    aes(x = title_position, y = -40, label = paste(\"Comm.\", community)),\n    colour = \"black\", alpha = 0.9, size = 2, fontface = \"bold\", inherit.aes = FALSE\n  )+\n  # --- Add the Title ---\n  labs(\n    title = \"Circular Bar Chart by Community\",\n    subtitle = \"Frequencies of key bigrams within each community\", # Updated subtitle\n    caption = paste0(\"AT | Generated: \", Sys.Date())\n  ) +\n  # Apply the Set2 Brewer palette\n  scale_fill_brewer(palette = \"Set2\") +\n  # --- Customize title appearance ---\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\", margin = margin(b = 10)),\n    plot.subtitle = element_text(hjust = 0.5, size = 12, margin = margin(b = 10)),\n    plot.caption = element_text(hjust = 1, size = 7, color = \"grey50\")\n  )\n\nprint(p)\n\n\n\n\n\n\n2.6 Community Group Membership- People & Vessels\nThe topic area was gathered from the bigram wordclouds and circular bar chart. The Group Name was created based on knowledge from the Members in the group and the topic area. These are the information for the 5 segmented groups:\n\nThe TableThe Code\n\n\n\n\n\nCommunity Group Membership Summary\n\n\n\n\n\n\n\n\nGroup Number\nTopic Area\nMembers\nGroup Name\n\n\n\n\n1\nnemo reef, himark harbor, samantha blake, city council\nDefender, EcoVigil, Horizon, Knowles, Mako, Marlin, Osprey, Reef Guardian, Samantha Blake, Seawatch, Sentinel, Serenity\nConservationist Group\n\n\n2\nsouth dock, equipment transfer, security team, nemo reef, delta3, cr 7844\nDavis, Elise, Liam Thorne, Nadia Conti, Neptune, Remora, Rodriguez, Small Fry\nPermit\n\n\n3\nintern reporting, conservation vessels, nemo reef\nKelly, Sam, The Intern, The Lookout\nPseudonym\n\n\n4\n10am tomorrow, 0500 tomorrow, funding channels, alternative funding\nBoss, Mrs. Money, The Accountant, The Middleman\nSuspicious\n\n\n5\nclassification markings, project poseidon, clearance documents, harbor security\nClepper Jensen, Miranda Jordan\nHacklee Herald\n\n\n\n\n\n\n\n\nset.seed(1234)\n# 6. Create a tidy summary table of members per community\ngrouped_members &lt;- g_pv %&gt;%\n  as_tibble() %&gt;%\n  select(name, community) %&gt;%\n  group_by(community) %&gt;%\n  summarise(\n    Members = paste(sort(name), collapse = \", \"),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    `Group Number` = community,\n    `Topic Area` = case_when(\n      community == 1 ~ \"nemo reef, himark harbor, samantha blake, city council\",\n      community == 2 ~ \"south dock, equipment transfer, security team, nemo reef, delta3, cr 7844\",\n      community == 3 ~ \"intern reporting, conservation vessels, nemo reef\",\n      community == 4 ~ \"10am tomorrow, 0500 tomorrow, funding channels, alternative funding\",\n      community == 5 ~ \"classification markings, project poseidon, clearance documents, harbor security\",\n      TRUE ~ \"Other\"\n    ),\n    `Group Name` = case_when(\n      community == 1 ~ \"Conservationist Group\",\n      community == 2 ~ \"Permit\",\n      community == 3 ~ \"Pseudonym\",\n      community == 4 ~ \"Suspicious\",\n      community == 5 ~ \"Hacklee Herald\",\n      TRUE ~ \"Miscellaneous\"\n    )\n  ) %&gt;%\n  select(`Group Number`, `Topic Area`, `Members`, `Group Name`)\n\n# Show the summary table in a clean format\nkable(grouped_members, caption = \"Community Group Membership Summary\", align = \"l\")\n\n\n\n\n\n\n\n\n\n\n2.6.1 Findings\n\n\n\n\nMovements and changes in membership since section 1.1.2:\n\nMako moved from Maritime to Conservationist.\nSamantha Blake moved from the Suspicious Characters to Conservationist.\nSam and Kelly moved from their own Community to Pseudonym.\nThe Lookout moved from Conservationist Group to Pseudonym.\nThe Intern moved from Suspicious Characters to Pseudonym.\nSailor Shift community renamed to Permit\n\nFrom 11 nodes, we further narrowed down on the 8 nodes in the suspicious groups named:\n\nPermit (Influential Nodes: Neptune, Remora, Nadia, Davis);\nConservationist Group (Influential Node: Mako);\nSuspicious (Influential Nodes: Mrs. Money, Boss, The Middleman).\n\nWe held back on the slightly less influential nodes such as: Hacklee Herald which was where Clepper Jensen worked as a journalist.\n\n\n\n\n\n2.7 Discussion/ Interpretation:\nWe mainly focused on the conversations by 8 influential nodes and some related nodes:\n\nConservation Group (Comm.1): Samantha Blake informed Mako to stop operations on 8 and 10th Oct. Serenity is a private luxury yacht. Osprey was likely a tourism vessel looking for charter from Mako for their tourists.\nPermit (Comm. 2): Neptune, Remora, Nadia, and Davis were working on Nemo Reef operation. This referred to the Music Video Production for Sailor Shift on 14 Oct.\n*Pseudonym* (Comm. 3): Other than communicating among themselves, The Lookout appeared to have also externally corresponded with Sentinel, Reef Guardian and Horizon (conservation based topics), while The Intern also externally corresponded with Mrs. Money.\nSuspicious (Comm. 4): The Middleman had access to Council documents. Mrs. Money had funding from sources that would not flag out to regulators for her operations. Mrs. Money was investigating V. Miesel’s structures. On 5 Oct, Boss told Mrs. Money to disguise financial trails through tourism ventures and destroy evidence of Nemo Reef operations.\nHacklee Herald (Comm. 5): Conversations between Clepper and his intern Miranda which ended on 11 Oct. Miranda mentioned an Oceanus City Council Member meeting with unmarked vessels at night."
  },
  {
    "objectID": "tasks.html#manual-mapping",
    "href": "tasks.html#manual-mapping",
    "title": "🌊 Visual Analysis Finding 🪸",
    "section": "Manual Mapping",
    "text": "Manual Mapping\n\nname_mapping &lt;- tibble::tibble(\n  observed_name = c(\n    \"Boss\", \"City Officials\", \"Clepper Jensen\", \"Davis\", \"Defender\", \"EcoVigil\",\n    \"Elise\", \"Glitters Team\", \"Green Guardians\", \"Haacklee Harbor\", \"Himark Harbor\", \"Horizon\",\n    \"Kelly\", \"Knowles\", \"Liam Thorne\", \"Mako\", \"Marlin\", \"Miranda Jordan\",\n    \"Mrs. Money\", \"Nadia Conti\", \"Neptune\", \"Northern Light\", \"Oceanus City Council\", \"Osprey\",\n    \"Paackland Harbor\", \"Port Security\", \"Reef Guardian\", \"Remora\", \"Rodriguez\", \"Sailor Shift Team\",\n    \"Sam\", \"Samantha Blake\", \"Seawatch\", \"Sentinel\", \"Serenity\", \"Small Fry\",\n    \"The Accountant\", \"The Intern\", \"The Lookout\", \"The Middleman\", \"V. Miesel Shipping\"\n  ),\n  real_identity = c(\n    \"Nadia Conti\", \"Oceanus City Council\", \"Clepper Jensen\", \"Captain Davis\", \"Sentinel\", \"EcoVigil\",\n    \"Elise\", \"Sailor Shift Team\", \"Green Guardians\", \"Harbor Authority\",\"Harbor Authority\", \"Horizon\",\n    \"Kelly\", \"Knowles\", \"Liam Thorne\", \"Mako\", \"Small Fishing Vessel\", \"Miranda Jordan\",\n    \"Elise\", \"Nadia Conti\", \"Neptune\", \"Commercial Vessel\", \"Oceanus City Council\", \"Tourism Vessel\",\n    \"Harbor Authority\", \"Oceanus City Council\", \"Reef Guardian\", \"Remora\", \"Rodriguez\", \"Sailor Shift Team\",\n    \"Sam\", \"Samantha Blake\", \"Kelly\", \"Sentinel\", \"Private Luxury Yacht\", \"Rodriguez\",\n    \"Elise\", \"Sam\", \"Kelly\", \"Liam Thorne\", \"V. Miesel Shipping\"\n  ),\n  community = c(\n    \"V. Miesel Shipping\", \"City Council\", \"Haacklee Herald\", \"V. Miesel Shipping\", \"Local Conservationist Group\", \"Local Conservationist Group\",\n    \"V. Miesel Shipping\", \"Sailor Shift Team\", \"Local Conservationist Group\", \"Harbor Authority\", \"Harbor Authority\", \"Local Conservationist Group\",\n    \"Local Conservationist Group\", \"V. Miesel Shipping\", \"City Council\", \"V. Miesel Shipping\", \"Maritime\", \"Haacklee Herald\",\n    \"V. Miesel Shipping\", \"V. Miesel Shipping\", \"V. Miesel Shipping\", \"Maritime\", \"City Council\", \"Maritime\",\n    \"Harbor Authority\", \"City Council\", \"Local Conservationist Group\", \"V. Miesel Shipping\", \"V. Miesel Shipping\", \"Sailor Shift Team\",\n    \"V. Miesel Shipping\", \"Sailor Shift Team\", \"Local Conservationist Group\", \"Local Conservationist Group\", \"Maritime\", \"V. Miesel Shipping\",\n    \"V. Miesel Shipping\", \"V. Miesel Shipping\", \"Local Conservationist Group\", \"City Council\", \"V. Miesel Shipping\"\n  )\n)\n\nmulti_members &lt;- tibble::tibble(\n  observed_name = c(\n    #  City Council members (additional to existing)\n    \"Commissioner Blake\", \"Commissioner Torres\", \"Council Knowles\", \"The Middleman\", \"Jensen from City Council\", \"Liam Thorne\",\n\n    # Sailor Shift Team (may already exist, but we ensure all)\n    \"Boss\", \"Council Knowles\", \"Davis\", \"Glitters Team\", \"Liam Thorne\", \"Mako\", \"Mrs. Money\", \"Nadia Conti\", \"Neptune\",\n    \"Remora\", \"Rodriguez\", \"Sam\", \"Samantha Blake\", \"Small Fry\", \"The Accountant\", \"The Intern\", \"The Middleman\", \"Elise\",\n\n    #  Influential Families\n    \"Council Knowles\", \"V. Miesel Shipping\",\n\n    #  Conservationist Group\n    \"Defender\", \"EcoVigil\", \"Green Guardians\", \"Horizon\", \"Kelly\", \"Reef Guardian\", \"Seawatch\", \"Sentinel\", \"The Lookout\"\n  ),\n  real_identity = c(\n    \"Commissioner Blake\", \"Commissioner Torres\", \"Council Knowles\", \"Liam Thorne\", \"Clepper Jensen\", \"Liam Thorne\",\n\n    \"Nadia Conti\", \"Council Knowles\", \"Captain Davis\", \"Sailor Shift Team\", \"Liam Thorne\", \"Mako\", \"Elise\", \"Nadia Conti\", \"Neptune\",\n    \"Remora\", \"Rodriguez\", \"Sam\", \"Samantha Blake\", \"Rodriguez\", \"Elise\", \"Sam\", \"Liam Thorne\", \"Elise\",\n\n    \"Council Knowles\", \"V. Miesel Shipping\",\n\n    \"Sentinel\", \"EcoVigil\", \"Green Guardians\", \"Horizon\", \"Kelly\", \"Reef Guardian\", \"The Lookout\", \"Sentinel\", \"Kelly\"\n  ),\n  community = c(\n    rep(\"City Council\", 6),\n    rep(\"Sailor Shift Team\", 18),\n    rep(\"Influential Families\", 2),\n    rep(\"Local Conservationist Group\", 9)\n  )\n)"
  },
  {
    "objectID": "tasks.html#discussioninterpretation-1-3-hop-data",
    "href": "tasks.html#discussioninterpretation-1-3-hop-data",
    "title": "🌊 Visual Analysis Finding 🪸",
    "section": "4.5 Discussion/Interpretation (1 & 3 hop data):",
    "text": "4.5 Discussion/Interpretation (1 & 3 hop data):\nThere were certain questions we posted to ourselves and came out with the answers.\n\n4.5.1 The Community and Ego Network:\n\nQuestion and Answer Analysis\n\n\n\n\n\n\n\nQuestion\nAnswer\n\n\n\n\nWho were Nadia’s direct communication contacts (1-hop degree centrality)? Are any of them known to be suspicious or involved in illicit activities?\nFrom the thicker width in the Ego network, it appeared that Nadia often communicated with Liam, Elise, and Davis.\nLiam appeared to be The Middleman within Nadia’s direct community from the Louvain Community Network.\nFrom the filtered table on suspicious relationships, Elise, Liam, EcoVigil, Sentinel, Oceanus City Council, and V. Miesel Shipping were noted to have suspicious relationships.\nTheir conversations were the area of focus to uncover their roles, relationships and identities.\n\n\nWere there any other ‘Event’ or ‘Relationship’ nodes directly connected to Nadia in this communication network that hinted at suspicious people/ activities?\nBased on information from question 2, Rodriguez was previously involved in mining activities that affected the environment. ‘Mining’ as a topic and his conversations would be tracked.\n\n\n\n\n\n\n4.5.2 The Communication Timeline and Content:\nIn the nadia_full_communications_timeline table, the actual content of her direct two-way communications were investigated over the course of 9 days. There were certain suspicious entities, keywords, coded language, or unusual topics detected that were suspicious. We have tabled out the segmented suspicious and non-suspicious entities for investigation and elimination.\n\nNot in the Network but Mentioned in the ContentSuspicious EntityNon Suspicious Entity\n\n\n\n\n\n\n\n\n\n\n\nEntity\nForm of Subject Matter\nRationale\nEvent ID\n\n\n\n\nNemo Reef\nLocation\nLikely conservation area which was picked by the characters for illicit activities.\n331, 943\n\n\nPermit #CR-7844\nItem\nLikely a permit to show tourism activity as a cover for suspicious activities. Rodriguez is likely linked to vessels Mako, Neptune, and Remora operating under this permit with a tourism facade.\n582, 847, 805\n\n\nEcoVigil\nVessel\nEcoVigil will likely affect Nadia’s operations when they use their ROV. Nadia recommended to V. Miesel to accelerate the planned operation. They were likely working for different sides.\n753, 847\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuspicious Entity\nSub Type\nCommunity\nRationale\nEvent ID\n\n\n\n\nHaacklee Harbor\nLocation\n2\nNadia’s communication to Haacklee Harbor is suspicious when she wanted the documents destroyed and the special corridor to Nemo Reef cancelled.\n331\n\n\nLiam aka The Middleman\nPerson\n2\nNadia wanted him to double his usual fee to ensure Harbor Master remains cooperative. Identity revealed through:\n529, 795, 847\n\n\nDavis\nPerson\n1\nNadia told him to create a clean paper trail. She will provide permits.\n521\n\n\nElise aka Mrs. Money\nPerson\n1\nNadia warned Elise that conservation vessels might complicate their operation. Identity revealed through:\n708, 528, 538, 677\n\n\nRodriguez aka Small Fry\nPerson\n1\nLinked to Mako, which is operating under a permit with a tourism facade.\n805\n\n\nRemora\nVessel\n1\nRemora reported a tourism facade to Nadia and planned underwater lighting placements in Nemo Reef while monitoring conservation vessels.\n943\n\n\nNeptune\nVessel\n1\nNadia told Neptune to stay under the radar.\n538\n\n\nV. Miesel HQ\nOrganisation\n1\nOrganisation was aware of the suspicious permit and The Middleman.\n846, 847\n\n\nSailor Shifts Team aka Glitters Team\nOrganisation\n1\nNadia provided crew members for the setup related to the permit.\n520\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon Suspicious Entity\nSub Type\nCommunity\nRationale\nEvent ID\n\n\n\n\nOceanus City Council\nOrganisation\n2\nOceanus City Council as a whole is not suspicious as an organisation as Liam stated this organisation suspected nothing.\n535\n\n\nSentinel\nVessel\n2\nSentinel Vessel suspected ulterior motives as the water quality was fine.\n677\n\n\nMarlin\nVessel\n2\nMarlin inquired about unusual vessel routes near eastern shoals, Nadia and Davis might need to address this.\n584"
  },
  {
    "objectID": "tasks.html#querying-keywords",
    "href": "tasks.html#querying-keywords",
    "title": "🌊 Visual Analysis Finding 🪸",
    "section": "4.6 Querying Keywords",
    "text": "4.6 Querying Keywords\nBased on our knowledge, we decided to connect to external information. We used knowledge from Nadia’s current network and communication with keyword search of our queries.\n\n4.6.1 Plotted Timeline (Word Query: Permit related)\n\n\nShow the code\n# -- Step 1: Define keywords\nkeywords &lt;- c(\"permit\", \"1045\", \"7844\")\npattern &lt;- paste0(\"\\\\b(\", paste(keywords, collapse = \"|\"), \")\\\\b\")\n\n# -- Step 2: Filter messages with keyword match (case-insensitive)\nkeyword_matches_df &lt;- other_communications_df %&gt;%\n  mutate(content_lower = tolower(content)) %&gt;%\n  filter(str_detect(content_lower, pattern))\n\n# -- Step 3: Extract and annotate keyword matches\nplot_data &lt;- keyword_matches_df %&gt;%\n  mutate(\n    matched_keywords = str_extract_all(content_lower, pattern),\n    timestamp = suppressWarnings(as.POSIXct(timestamp)),\n    comm_date = as.Date(timestamp),\n    comm_time_of_day = suppressWarnings(hms::as_hms(format(timestamp, \"%H:%M:%S\"))),\n    wrapped_content = str_wrap(content, width = 50)\n  ) %&gt;%\n  unnest(matched_keywords) %&gt;%\n  mutate(\n    matched_keywords = recode(matched_keywords,\n      \"permit\" = \"Permit\",\n      \"1045\" = \"# 1045\",\n      \"7844\" = \"# 7844\"\n    ),\n    tooltip_text = paste0(\n      \"&lt;b&gt;Date:&lt;/b&gt; \", comm_date,\n      \"&lt;br&gt;&lt;b&gt;Time:&lt;/b&gt; \", format(comm_time_of_day, \"%H:%M:%S\"),\n      \"&lt;br&gt;&lt;b&gt;Event ID:&lt;/b&gt; \", event_id,\n      \"&lt;br&gt;&lt;b&gt;Content:&lt;/b&gt;&lt;br&gt;\", wrapped_content\n    )\n  )\n\n# -- Step 4: Plot timeline\np &lt;- ggplot(plot_data, aes(x = comm_date, y = comm_time_of_day)) +\n  geom_point(aes(\n    color = matched_keywords,\n    shape = sender_sub_type,\n    text = tooltip_text,\n    group = matched_keywords\n  ), size = 2.5, alpha = 0.7, show.legend = TRUE) +\n  scale_shape_manual(values = c(\n    \"Person\" = 16,\n    \"Vessel\" = 17,\n    \"Organization\" = 15,\n    \"Location\" = 18\n  )) +\n  facet_wrap(~ matched_keywords, ncol = 1, scales = \"fixed\") +\n  scale_y_time(\n    limits = hms::as_hms(c(\"08:00:00\", \"13:00:00\")),\n    breaks = hms::as_hms(c(\"08:00:00\", \"09:00:00\", \"10:00:00\", \"11:00:00\", \"12:00:00\", \"13:00:00\")),\n    labels = c(\"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\")\n  ) +\n  scale_x_date(date_breaks = \"1 day\", date_labels = \"%d %b\") +\n  labs(\n    title = \"Interactive Timeline: Keyword Mentions by Day and Time\",\n    x = \"Date\",\n    y = \"Time of Day\",\n    shape = \"Sender Type\",\n    color = \"Keyword\"\n  ) +\n  theme_grey() +\n  theme(\n    axis.text.y = element_text(size = 6),\n    axis.title.y = element_text(size = 7),\n    axis.ticks.y = element_line(),\n    axis.text.x = element_text(size = 6, angle = 45, hjust = 1),\n    axis.title.x = element_text(margin = margin(t = 10), size = 7),\n    panel.spacing = unit(0.5, \"lines\"),\n    strip.text = element_text(size = 8, face = \"bold\"),\n    legend.position = \"bottom\",\n    legend.text = element_text(size = 6),\n    legend.title = element_blank()\n  )\n\n# -- Step 5: Convert to plotly\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n4.6.1.1 Findings in sequential order:\n\nThere were overlaps as the blue permit also included the red NR-1045 permit and green CR-7844 permit.\n\n\n\nShow the code\nlibrary(reactable)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(readr) # Used for read_lines\n\n# 1. Prepare data from the text provided\ndata_text &lt;- \"\nDate & Time | Event Description\n------------|---------------------------------------------------------------------------------------------------------------\n2 Oct (12:16pm) | Rodriguez was from the Sailor Shifts Team.\n5 Oct (10:54am) | Jensen from City Council approved Nemo Reef permit.\n6 Oct (9:57am) | Remora told Sailor Shifts Team that Nadia got Commissioner Torres to sign off the permit.\n6 Oct (10:45am) | Mako acknowledged NR-1045 permit to Nemo Reef.\n6 Oct (12:33pm) | Mako was lead vessel to Neptune and Remora as authorised by V. Miesel Shipping.\n7 Oct (9:40am) | Mako was operating under permit NR-1045 for conservation research.\n8 Oct (10:24am) | Mako was operating under V. Miesel's special marine research permit CR-7844 approved by Oceanus City Council.\n8 Oct (10:30am) | Mako informed Remora that both of them were operating under permit CR-7844 and have a 5 day deadline.\n8 Oct (10:40am) | Remora was approved by Paackland Harbor to operate with extended hours under permit NR-1045.\n9 Oct (11:53am) | Mako requesed for additional crew from v Miesel Shipping for the 24hr operations over next 5 days.\n11 Oct (6:00am) | Nemo Reef closure mandated by Oceanus City Council.\n11 Oct (8:57am) | All research permits must be submitted within 72 hours.\n11 Oct (10:05am) | V. Miesel Shipping informed Remora that 30% of her crew to be reassigned to Neptune.\n12 Oct (10:01am) | Davis as Captain oversaw crew reallocation.\n12 Oct (11:19am) | Nadia secured documentation for CR-7844.\n12 Oct (12:52pm) | Harbor closure for 3 days from 13 Oct 06:00.\n\"\n\n# Parse the data into a data frame\n# Use read_lines to handle the multi-line string\ndata_lines &lt;- read_lines(data_text)\n\n# Remove the header separator line and any empty lines\ndata_lines &lt;- data_lines[!grepl(\"^---|===\", data_lines) & data_lines != \"\"]\n\n# The first non-separator line is the header\ncol_names_raw &lt;- str_split(data_lines[1], \"\\\\|\")[[1]]\ncol_names &lt;- str_trim(col_names_raw)\n\n# The rest are data rows\ndata_content &lt;- data_lines[-1]\n\n# Create data frame by splitting lines and putting into a tibble\ndf &lt;- tibble(line = data_content) %&gt;%\n  mutate(\n    `Date & Time` = str_trim(str_extract(line, \"^[^|]+\")),\n    `Event Description` = str_trim(str_extract(line, \"(?&lt;=\\\\|).+$\"))\n  ) %&gt;%\n  select(`Date & Time`, `Event Description`) # Ensure correct column order and names\n\n# 2. Create the reactable table with desired features\n\nreactable(\n  df,\n  filterable = TRUE, # Enable column-specific filters (from the tutorial)\n  searchable = TRUE, # Enable global search box (from the tutorial)\n  paginationType = \"numbers\", # Display page numbers (corrected from \"pages\")\n  defaultPageSize = 5, # Show 5 rows per page\n  showPageSizeOptions = TRUE, # Allow users to change page size\n  pageSizeOptions = c(5, 10, 15, 20, 50), # Options for page sizes\n  striped = TRUE, # Add alternating row colors (from the tutorial)\n  highlight = TRUE, # Highlight row on hover (from the tutorial)\n  columns = list(\n    `Date & Time` = colDef(\n      name = \"Date & Time\",\n      minWidth = 120, # Adjust width to fit content\n      align = \"left\"\n    ),\n    `Event Description` = colDef(\n      name = \"Event Description\",\n      minWidth = 500, # Ensure enough width for event descriptions\n      align = \"left\"\n    )\n  ),\n  # Apply a custom theme for better aesthetics (inspired by the tutorial)\n  theme = reactableTheme(\n    borderColor = \"#dfe2e5\",\n    stripedColor = \"#f6f8fa\",\n    highlightColor = \"#f0f5f9\",\n    cellPadding = \"8px 12px\",\n    style = list(fontFamily = \"Verdana, Geneva, sans-serif\", fontSize = \"14px\"),\n    headerStyle = list(\n      \"&.rt-th:hover\" = list(backgroundColor = \"#e0e6eb\"),\n      fontSize = \"15px\",\n      fontWeight = 600,\n      color = \"#333\", # Darker header text for contrast\n      background = \"#f7f7f7\" # Slightly grey background for header\n    ),\n    rowSelectedStyle = list(backgroundColor = \"#e6f2ff\", \"&:hover\" = list(backgroundColor = \"#e6f2ff\")),\n    # Styles for search/filter inputs (from tutorial's theme example)\n    searchInputStyle = list(width = \"100%\", margin = \"5px 0\", padding = \"5px\"),\n    filterInputStyle = list(width = \"100%\", margin = \"2px 0\", padding = \"4px\")\n  )\n)\n\n\n\n\n\n\n\nSince there were little communications on 13 Oct, we looked into other word queries.\nUsing information obtained from question 2 and 4, we had in mind certain keywords to query for.\n\n\n\n4.6.2 Plotted Timeline (Word Query: Music Video Related)\n\n\nShow the code\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(hms)\nlibrary(tidyr)\n\n# -- Step 1: Define keywords\nkeywords &lt;- c(\"mine\", \"mining\", \"music video\", \"lighting\", \"reef operation\")\npattern &lt;- paste0(\"\\\\b(\", paste(keywords, collapse = \"|\"), \")\\\\b\")\n\n# -- Step 2: Filter messages\nsearch_target_content &lt;- tolower(other_communications_df$content)\n\nkeyword_matches_df &lt;- other_communications_df %&gt;%\n  filter(str_detect(search_target_content, pattern))\n\n# -- Step 3: Extract keywords\nplot_data &lt;- keyword_matches_df %&gt;%\n  mutate(matched_keywords = str_extract_all(tolower(content), pattern)) %&gt;%\n  unnest(matched_keywords) %&gt;%\n  mutate(matched_keywords = str_to_title(matched_keywords)) %&gt;%\n  arrange(matched_keywords, timestamp) %&gt;%\n  mutate(\n    timestamp = as.POSIXct(timestamp),\n    comm_date = as.Date(timestamp),\n    comm_time_of_day = hms::as_hms(format(timestamp, \"%H:%M:%S\")),\n    wrapped_content = str_wrap(content, width = 50),\n    tooltip_text = paste0(\n      \"&lt;b&gt;Date:&lt;/b&gt; \", comm_date,\n      \"&lt;br&gt;&lt;b&gt;Time:&lt;/b&gt; \", comm_time_of_day,\n      \"&lt;br&gt;&lt;b&gt;Event ID:&lt;/b&gt; \", event_id,\n      \"&lt;br&gt;&lt;b&gt;From:&lt;/b&gt; \", sender_name,\n      \"&lt;br&gt;&lt;b&gt;To:&lt;/b&gt; \", recipient_name,\n      \"&lt;br&gt;&lt;b&gt;Content:&lt;/b&gt;&lt;br&gt;\", wrapped_content\n    )\n  )\n\n# -- Step 4: Plot\np &lt;- ggplot(plot_data, aes(x = comm_date, y = comm_time_of_day)) +\n  geom_point(aes(\n    color = matched_keywords,\n    shape = sender_sub_type,\n    text = tooltip_text,\n    group = matched_keywords  # ensures matched_keywords is in layer\n  ), size = 2.5, alpha = 0.7, show.legend = TRUE) +\n  scale_shape_manual(values = c(\n    \"Person\" = 16,\n    \"Vessel\" = 17,\n    \"Organization\" = 15,\n    \"Location\" = 18\n  )) +\n  facet_wrap(~ matched_keywords, ncol = 1, scales = \"fixed\") +\n  scale_y_time(\n    limits = hms::as_hms(c(\"08:00:00\", \"13:00:00\")),\n    breaks = hms::as_hms(c(\"08:00:00\", \"09:00:00\", \"10:00:00\", \"11:00:00\", \"12:00:00\", \"13:00:00\")),\n    labels = c(\"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\")\n  ) +\n  scale_x_date(date_breaks = \"1 day\", date_labels = \"%d %b\") +\n  labs(\n    title = \"Interactive Timeline: Keyword Mentions by Day and Time\",\n    x = \"Date\",\n    y = \"Time of Day\",\n    shape = \"Sender Type\",\n    color = \"Keyword\"\n  ) +\n  theme_grey() +\n  theme(\n    axis.text.y = element_text(size = 6),\n    axis.title.y = element_text(size = 7),\n    axis.ticks.y = element_line(),\n    axis.text.x = element_text(size = 6, angle = 45, hjust = 1),\n    axis.title.x = element_text(margin = margin(t = 10), size = 7),\n    panel.spacing = unit(0.5, \"lines\"),  # Applies to both x and y spacing\n    strip.text = element_text(size = 8, face = \"bold\"),\n    legend.position = \"bottom\",\n    legend.text = element_text(size = 6),\n    legend.title = element_blank()\n  )\n\n# -- Step 5: Convert to plotly\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n4.6.2.1 Findings through Questions & Answers:\n\nQuestion and Answer Analysis\n\n\n\n\n\n\n\nQuestion\nAnswer\n\n\n\n\nWhich vessel was the suspicious permit #CR-7844 prepared for?\n(See 4.6.1.1)\nFrom question 2 and 4, we know this is V. Miesel’s Marine Research Permit, and prepared for Mako (lead vessel), Neptune, and Remora.\n\n\nWhat suspicious activity was performed at Nemo Reef? Which day was it?\n(See 4.6.2)\n14 Oct 2040 for a music video production.\n\n\nWhy is underwater lighting placement needed at Nemo Reef?\n(See 4.6.2)\nFor a music video production.\n\n\nWhat were the expedited approvals and secretive logistics?\n(See 4.6.1 and 4.6.2)\nPermits for Nemo Reef through NR-1045 and CR-788 were expedited. The secretive logistics were the crates and equipment on the vessels for the music video production.\n\n\nWho were the high-level Oceanus officials, Sailor Shift’s team, local influential families, and local conservationist group?\n(Various Ids)\nOceanus Officials: Commissioner Blake, Commissioner Torres, Council Knowles, The Middleman, Jensen, Liam Thorne\nSailor Shift’s Team: Boss, Council Knowles, Davis, Glitters Team, Liam Thorne, Mako, Mrs. Money, Nadia, Neptune, Remora, Rodriguez, Sam, Samantha Blake, Small Fry, The Accountant, The Intern, The Middleman\nLocal Influential Families: Council Knowles, V. Miesel Shipping\nLocal Conservationist Group: Defender, EcoVigil, Green Guardians, Horizon, Kelly, Reef Guardians, Seawatch, Sentinel, The Lookout\n\n\nWas the music video production activity legal?\n(Id 979)\nThere was no environmental damage or mining involved in the music production. However, an environmental assessment was not conducted prior. Clepper may assess that his suspicions about Nadia Conti’s illicit activity may not be straightforward and could depend on whether an assessment was mandatory before commercial activities."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "🌊 Project Introduction 🪸",
    "section": "",
    "text": "In this study, we will be tackling Mini-case 3 of VAST Challenge 2025.\n\n\nOver the past decade, the community of Oceanus has faced numerous transformations and challenges evolving from its fishing-centric origins. Following major crackdowns on illegal fishing activities, suspects have shifted investments into more regulated sectors such as the ocean tourism industry, resulting in growing tensions. This increased tourism has recently attracted the likes of international pop star Sailor Shift, who announced plans to film a music video on the island.\nClepper Jensen, a former analyst at FishEye and now a seasoned journalist for the Hacklee Herald, has been keenly observing these rising tensions. Recently, he turned his attention towards the temporary closure of Nemo Reef. By listening to radio communications and utilizing his investigative tools, Clepper uncovered a complex web of expedited approvals and secretive logistics. These efforts revealed a story involving high-level Oceanus officials, Sailor Shift’s team, local influential families, and local conservationist group The Green Guardians, pointing towards a story of corruption and manipulation.\nOur task is to develop new and novel visualizations and visual analytics approaches to help Clepper get to the bottom of this story.\n\n\n\nClepper diligently recorded all intercepted radio communications over the last two weeks. With the help of his intern, they have analyzed their content to identify important events and relationships between key players. The result is a knowledge graph describing the last two weeks on Oceanus. Clepper and his intern have spent a large amount of time generating this knowledge graph, and they would now like some assistance using it to answer the following 4 questions.\n\nQuestion 1\nClepper found that messages frequently came in at around the same time each day.\n1a. Develop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\n1b. How do these patterns shift over the two weeks of observations?\n1c. Focus on a specific entity and use this information to determine who has influence over them.\nQuestion 2\nClepper has noticed that people often communicate with (or about) the same people or vessels, and that grouping them together may help with the investigation.\n2a. Use visual analytics to help Clepper understand and explore the interactions and relationships between vessels and people in the knowledge graph.\n2b. Are there groups that are more closely associated? If so, what are the topic areas that are predominant for each group?\n\nFor example, these groupings could be related to: Environmentalism (known associates of Green Guardians), Sailor Shift, and fishing/leisure vessels.\n\nQuestion 3\nIt was noted by Clepper’s intern that some people and vessels are using pseudonyms to communicate.\n3a. Expanding upon your prior visual analytics, determine who is using pseudonyms to communicate, and what these pseudonyms are.\n\nSome that Clepper has already identified include: “Boss”, and “The Lookout”, but there appear to be many more.\nTo complicate the matter, pseudonyms may be used by multiple people or vessels.\n\n3b. Describe how your visualizations make it easier for Clepper to identify common entities in the knowledge graph.\n3c. How does your understanding of activities change given your understanding of pseudonyms?\nQuestion 4\nClepper suspects that Nadia Conti, who was formerly entangled in an illegal fishing scheme, may have continued illicit activity within Oceanus.\n4a. Through visual analytics, provide evidence that Nadia is, or is not, doing something illegal.\n4b. Summarize Nadia’s actions visually. Are Clepper’s suspicions justified?"
  },
  {
    "objectID": "intro.html#background-and-questions",
    "href": "intro.html#background-and-questions",
    "title": "🌊 Project Introduction 🪸",
    "section": "",
    "text": "In this study, we will be tackling Mini-case 3 of VAST Challenge 2025.\n\n\nOver the past decade, the community of Oceanus has faced numerous transformations and challenges evolving from its fishing-centric origins. Following major crackdowns on illegal fishing activities, suspects have shifted investments into more regulated sectors such as the ocean tourism industry, resulting in growing tensions. This increased tourism has recently attracted the likes of international pop star Sailor Shift, who announced plans to film a music video on the island.\nClepper Jensen, a former analyst at FishEye and now a seasoned journalist for the Hacklee Herald, has been keenly observing these rising tensions. Recently, he turned his attention towards the temporary closure of Nemo Reef. By listening to radio communications and utilizing his investigative tools, Clepper uncovered a complex web of expedited approvals and secretive logistics. These efforts revealed a story involving high-level Oceanus officials, Sailor Shift’s team, local influential families, and local conservationist group The Green Guardians, pointing towards a story of corruption and manipulation.\nOur task is to develop new and novel visualizations and visual analytics approaches to help Clepper get to the bottom of this story.\n\n\n\nClepper diligently recorded all intercepted radio communications over the last two weeks. With the help of his intern, they have analyzed their content to identify important events and relationships between key players. The result is a knowledge graph describing the last two weeks on Oceanus. Clepper and his intern have spent a large amount of time generating this knowledge graph, and they would now like some assistance using it to answer the following 4 questions.\n\nQuestion 1\nClepper found that messages frequently came in at around the same time each day.\n1a. Develop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\n1b. How do these patterns shift over the two weeks of observations?\n1c. Focus on a specific entity and use this information to determine who has influence over them.\nQuestion 2\nClepper has noticed that people often communicate with (or about) the same people or vessels, and that grouping them together may help with the investigation.\n2a. Use visual analytics to help Clepper understand and explore the interactions and relationships between vessels and people in the knowledge graph.\n2b. Are there groups that are more closely associated? If so, what are the topic areas that are predominant for each group?\n\nFor example, these groupings could be related to: Environmentalism (known associates of Green Guardians), Sailor Shift, and fishing/leisure vessels.\n\nQuestion 3\nIt was noted by Clepper’s intern that some people and vessels are using pseudonyms to communicate.\n3a. Expanding upon your prior visual analytics, determine who is using pseudonyms to communicate, and what these pseudonyms are.\n\nSome that Clepper has already identified include: “Boss”, and “The Lookout”, but there appear to be many more.\nTo complicate the matter, pseudonyms may be used by multiple people or vessels.\n\n3b. Describe how your visualizations make it easier for Clepper to identify common entities in the knowledge graph.\n3c. How does your understanding of activities change given your understanding of pseudonyms?\nQuestion 4\nClepper suspects that Nadia Conti, who was formerly entangled in an illegal fishing scheme, may have continued illicit activity within Oceanus.\n4a. Through visual analytics, provide evidence that Nadia is, or is not, doing something illegal.\n4b. Summarize Nadia’s actions visually. Are Clepper’s suspicions justified?"
  },
  {
    "objectID": "intro.html#the-data",
    "href": "intro.html#the-data",
    "title": "🌊 Project Introduction 🪸",
    "section": "1.2 The Data",
    "text": "1.2 The Data\nWe used the dataset provided by VAST Challenge. We were provided a knowledge graph created from transcripts of boat radio communications for two weeks on Oceanus. We were asked to identify people, their roles, and the events and locations they talked to get to the bottom of the story. This graph is a network data that contains nodes that represent the different entities, events, and relationships, and edges which represent the relationships between different nodes."
  },
  {
    "objectID": "intro.html#methodology",
    "href": "intro.html#methodology",
    "title": "🌊 Project Introduction 🪸",
    "section": "1.3 Methodology",
    "text": "1.3 Methodology\nTo answer these questions, we investigated the communications and relationships among entities. We did this by creating visualisation such as subgraphs of networks, chord diagrams, timeline plots, wordclouds, and circular bar charts. Then we tabled the findings, and discussion/ interpretations."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "🌊 Covert Reef Team Members 🪸",
    "section": "",
    "text": "Yang LuAudrey TanLi Jianyi\n\n\nMy name is Yang Lu, and I’m currently pursuing a Master at Singapore Management University, specializing in the Financial Technology& Analytics track. In this Visual Analytics and Applications course, I focus on harnessing the power of RStudio to transform complex financial datasets into clear, actionable insights. My work includes data wrangling with tidyverse, creating interactive visualizations with ggplot2 and plotly, and building dashboards using shiny. I am passionate about applying these skills to real-world fintech challenges and continuously learning new tools and techniques to advance my analytical toolkit.\n\n\n\n\n\n\nYang Lu\n\n\n\nPlease feel free to click on my LinkedIn and GitHub links for more info!   Linkedin  |   GitHub\n\n\n\n\nWrite something!!!!\n\n\n\n\n\n\nAudrey\n\n\n\nPlease feel free to click on my LinkedIn and GitHub links for more info!   Linkedin  |   GitHub\n\n\n\n\nMy name is Jianyi, and I came into the Visual Analytics module hoping to learn how to turn complex data into clear and engaging visuals. The module exceeded my expectations by equipping me with practical skills in R, Shiny, and Quarto, while also teaching me the importance of design, storytelling, and user experience in data communication. I especially enjoyed building interactive dashboards and applying visual thinking to real-world scenarios. I believe these skills will be valuable in future projects, business reporting, and communicating insights to both technical and non-technical audiences.\n\n\n\n\n\n\nJianyi\n\n\n\nPlease feel free to click on my LinkedIn and GitHub links for more info!   Linkedin  |   GitHub"
  },
  {
    "objectID": "datapre.html",
    "href": "datapre.html",
    "title": "🌊 Data Preparation 🪸",
    "section": "",
    "text": "To build this prototype module, we adopted a structured visual analytics approach, starting from data ingestion to visual storytelling. The knowledge graph provided in Mini-Challenge 3 was first cleaned, transformed, and modeled using tidygraph. Communication patterns, relationships, and anomalies were then extracted through modular analysis and visualized using both static (ggplot2, ggraph) and interactive (plotly, visNetwork) tools.\nThe overall methodology consists of the following stages:\n\nData Preparation We loaded and flattened the JSON-based knowledge graph, extracted nodes and edges, cleaned missing values, and validated the network structure for compatibility with tidygraph. Each entity was classified by type and sub-type to enable filtering and targeted analysis.\nModular Task Execution Each of the four investigative tasks was assigned to team member, allowing parallel and comparison development:\n\n\nTemporal trends were analyzed by aggregating communication timestamps by hour and date.\nEntity relationships were explored through network graph layouts and centrality measures.\nAnomaly detection used Z-score normalization on daily message counts.\nSuspicious activity was investigated through person-to-person messaging analysis.\n\n\nPrototype Development All modules were translated into reactive components suitable for a Shiny application. Input widgets such as selectInput(), dateRangeInput(), and checkboxGroupInput() allow user-driven filtering, while outputs include plotlyOutput() and visNetworkOutput() for dynamic and exploratory analysis.\nDesign and Storyboarding A UI storyboard was drafted to guide the layout of the final Shiny app, ensuring usability and clarity. Each module was built to function independently but integrate smoothly into the full application."
  },
  {
    "objectID": "datapre.html#defining-common-variables",
    "href": "datapre.html#defining-common-variables",
    "title": "🌊 Data Preparation 🪸",
    "section": "2.1 Defining common variables",
    "text": "2.1 Defining common variables\nWe will also set some values for consistency throughout all graphs.\n\nStyle and Colours\n\n\n\n\nShow the code\nnode_legend_colors_plot &lt;- c(\n  \"Person\" = \"#88CCEE\",\n  \"Vessel\" = \"#D55E00\",\n  \"Organization\" = \"#117733\",\n  \"Location\" = \"#AA4499\",\n  \"Group\"= \"#CC79A7\",\n  \"Event\" = \"#DDCC77\",\n  \"Relationship\" = \"#AF8DC3\",\n  \"Nadia Conti\" = \"red\"\n)\n\nnode_legend_shapes_plot &lt;- c(\n  \"Person\" = \"dot\",\n  \"Vessel\" = \"triangle\",\n  \"Organization\" = \"square\",\n  \"Location\" = \"diamond\",\n  \"Group\" = \"circle plus\",\n  \"Event\" = \"star\",\n  \"Relationship\" = \"square x\",\n  \"Nadia Conti\" = \"star\"\n)\n\nSTYLES &lt;- list(\n  node_label_dark = \"black\",\n  font_family = \"Roboto Condensed\"\n)"
  },
  {
    "objectID": "datapre.html#inspecting-knowledge-graph-structure",
    "href": "datapre.html#inspecting-knowledge-graph-structure",
    "title": "🌊 Data Preparation 🪸",
    "section": "2.2 Inspecting knowledge graph structure",
    "text": "2.2 Inspecting knowledge graph structure\nIn the code chunk below glimpse() is used to reveal the structure of mc3_data knowledge graph.\n\nThe CodeThe Result\n\n\nglimpse(mc3_data)\n\n\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame': 1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':   1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame': 3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ..."
  },
  {
    "objectID": "datapre.html#extracting-the-edges-and-nodes-tables",
    "href": "datapre.html#extracting-the-edges-and-nodes-tables",
    "title": "🌊 Data Preparation 🪸",
    "section": "2.3 Extracting the edges and nodes tables",
    "text": "2.3 Extracting the edges and nodes tables\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from mc3 tibble dataframe into two separate tibble dataframes called mc3_nodes_raw and mc3_edges_raw respectively.\n\nThe CodeNodes structureEdges structure\n\n\n\n\nShow the code\nmc3_nodes_raw &lt;- as_tibble(mc3_data$nodes)\nmc3_edges_raw &lt;- as_tibble(mc3_data$edges)\n\n\nWe also looked into the nodes and edges structure.\n\n\n\n\nShow the code\nExpData(data=mc3_nodes_raw,type=2)\n\n\n   Index     Variable_Name Variable_Type Sample_n Missing_Count Per_of_Missing\n1      1              type     character     1159             0          0.000\n2      2             label     character     1159             0          0.000\n3      3              name     character       72          1087          0.938\n4      4          sub_type     character     1159             0          0.000\n5      5                id     character     1159             0          0.000\n6      6         timestamp     character      770           389          0.336\n7      7   monitoring_type     character       70          1089          0.940\n8      8          findings     character       70          1089          0.940\n9      9           content     character      584           575          0.496\n10    10   assessment_type     character       33          1126          0.972\n11    11           results     character       32          1127          0.972\n12    12     movement_type     character       33          1126          0.972\n13    13       destination     character       41          1118          0.965\n14    14  enforcement_type     character       21          1138          0.982\n15    15           outcome     character       19          1140          0.984\n16    16     activity_type     character        4          1155          0.997\n17    17      participants       integer        1          1158          0.999\n18    18   thing_collected    data.frame    -2314          2316       1158.000\n19    19         reference     character        1          1158          0.999\n20    20              date     character        5          1154          0.996\n21    21              time     character        3          1156          0.997\n22    22   friendship_type     character        2          1157          0.998\n23    23   permission_type     character       55          1104          0.953\n24    24        start_date     character       90          1069          0.922\n25    25          end_date     character        6          1153          0.995\n26    26       report_type     character       19          1140          0.984\n27    27   submission_date     character       22          1137          0.981\n28    28 jurisdiction_type     character       13          1146          0.989\n29    29   authority_level     character        7          1152          0.994\n30    30 coordination_type     character       73          1086          0.937\n31    31  operational_role     character       38          1121          0.967\n   No_of_distinct_values\n1                      3\n2                     92\n3                     73\n4                     25\n5                   1159\n6                    612\n7                      6\n8                     70\n9                    581\n10                     4\n11                    33\n12                     4\n13                    26\n14                     3\n15                    20\n16                     3\n17                     1\n18                     2\n19                     2\n20                     6\n21                     4\n22                     3\n23                     4\n24                    69\n25                     6\n26                     4\n27                    23\n28                    13\n29                     3\n30                    53\n31                    35\n\n\n\n\n\n\nShow the code\nExpData(data=mc3_edges_raw,type=2)\n\n\n  Index Variable_Name Variable_Type Sample_n Missing_Count Per_of_Missing\n1     1            id     character     3169            57          0.018\n2     2   is_inferred       logical     3226             0          0.000\n3     3        source     character     3226             0          0.000\n4     4        target     character     3226             0          0.000\n5     5          type     character     2204          1022          0.317\n  No_of_distinct_values\n1                  3170\n2                     2\n3                  1052\n4                  1156\n5                     4"
  },
  {
    "objectID": "datapre.html#nodes-via-shiny",
    "href": "datapre.html#nodes-via-shiny",
    "title": "🌊 Data Preparation 🪸",
    "section": "3.1 Nodes via Shiny",
    "text": "3.1 Nodes via Shiny\n\nNodesDrilling into Node sub_typeEntity subtypesEvent subtypesRelationship subtypes\n\n\nIn the code chunk below, ExpCatViz() of SmartEDA package is used to reveal the frequency distribution of all categorical fields in mc3_nodes tibble dataframe.\n\n\nShow the code\nlibrary(shiny)\nlibrary(ggplot2)\n\n# Run ExpCatViz once at the top to avoid recomputing\nExpCatViz(data=mc3_nodes_raw,\n          col=\"navyblue\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below uses ggplot2 functions to reveal the frequency distribution of sub_type field of mc3_nodes_raw.\n\n\nShow the code\n# Step 1: Count and reorder\nmc3_nodes_ordered &lt;- mc3_nodes_raw %&gt;%\n  count(sub_type) %&gt;%\n  arrange((n)) %&gt;%\n  mutate(sub_type = factor(sub_type, levels = sub_type))\n\n# Step 2: Plot with navy bars, sorted, and horizontal\nggplot(mc3_nodes_ordered, aes(x = sub_type, y = n)) +\n  geom_col(fill = \"navy\") +\n  coord_flip() +\n  labs(x = \"Sub_type\", y = \"Count\",\n    title = \"Distribution of Subtypes\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Entity subtypes are filtered.\n\n\nShow the code\n# Step 1: Filter for type == \"Entity\", count sub_type, sort \nrelationship_subtypes &lt;- mc3_nodes_raw %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type) %&gt;%\n  arrange(n) %&gt;%\n  mutate(sub_type = factor(sub_type, levels = sub_type)) \n\n# Step 2: Plot\nggplot(relationship_subtypes, aes(x = sub_type, y = n)) +\n  geom_col(fill = \"navy\") +\n  coord_flip() +\n  labs(\n    x = \"Entity Subtype\",\n    y = \"Count\",\n    title = \"Distribution of Entity Subtypes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Event subtypes are filtered.\n\n\nShow the code\n# Step 1: Filter for type == \"Event\", count sub_type, sort \nrelationship_subtypes &lt;- mc3_nodes_raw %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type) %&gt;%\n  arrange(n) %&gt;%\n  mutate(sub_type = factor(sub_type, levels = sub_type)) \n\n# Step 2: Plot\nggplot(relationship_subtypes, aes(x = sub_type, y = n)) +\n  geom_col(fill = \"navy\") +\n  coord_flip() +\n  labs(\n    x = \"Event Subtype\",\n    y = \"Count\",\n    title = \"Distribution of Event Subtypes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the relationship subtypes are filtered.\n\n\nShow the code\n# Step 1: Filter for type == \"Relationship\", count sub_type, sort \nrelationship_subtypes &lt;- mc3_nodes_raw %&gt;%\n  filter(type == \"Relationship\") %&gt;%\n  count(sub_type) %&gt;%\n  arrange(n) %&gt;%\n  mutate(sub_type = factor(sub_type, levels = sub_type))\n\n# Step 2: Plot\nggplot(relationship_subtypes, aes(x = sub_type, y = n)) +\n  geom_col(fill = \"navy\") +\n  coord_flip() +\n  labs(\n    x = \"Relationship Subtype\",\n    y = \"Count\",\n    title = \"Distribution of Relationship Subtypes\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "datapre.html#findings-from-eda",
    "href": "datapre.html#findings-from-eda",
    "title": "🌊 Data Preparation 🪸",
    "section": "3.1.1 Findings from EDA",
    "text": "3.1.1 Findings from EDA\n\nNodesEvent TypesRelationship TypesEntity TypesCourse of Action\n\n\nWe will use the EDA findings to determine data to focus on or eliminate. From the bar charts and the original data on mc3_nodes_raw, it was observed that:\n\nNodes were one of three types (Entity, Event, Relationship), where each of these types have their sub_types. Majority were of event type, followed by relationship, and entity.\n\nThere were 25 subtypes. Communications made up the bulk of the sub_type for Events. Coordinates made up the bulk of the sub_type for Relationship. The additional node sub_types not mentioned in the VAST 2025 MC3 Data Description under Node Attributes were: fishing, communication and coordinates.\n\n\n\n\n\nObservations of EDA from Event types:\n\nFindings field were filled when there were monitoring_type.\nContent refers to radio communication content.\nResults field were filled when there were assessment_type performed.\nWhen there is an enforcement_type of enforcement operations or warnings, there might be an outcome at times.\nWhen there is a movement_type, there might be a place of destination at times.\n\n\n\n\n\nObservations of EDA from Relationship types:\n\nWhen the subtype was coordinate, there were data in the field named coordination_types.\nWhen the subtype was operate, there were data in the field named operational_roles.\nWhen there is a jurisdiction_type, there might be an authority_level.\nThere are only restricted or special access data within permission_types.\nWhen there is a report_type of data transmission or environmental report, there might be a submission_date.\n\n\n\n\n\nObservations of EDA from Entity types:\n\nThe 5 id under Group sub-types were not very useful information.\n\n\n\n\n\nElimination and directed focus:\n\nRelative to the entire dataset, there were little assessment_type (3%), movement_type (2%), enforcement_type (2%), permission_type (4%), report_type (2%), authority_level (1%). We will direct our focus on other areas instead of these.\nThere were no to little useful data in the fields named: activity_type, references, dates, time, and friendship_type. These were not utilised.\nWe directed our focus on Event_Communication, Event_Monitoring, and Event_VesselMovement."
  },
  {
    "objectID": "datapre.html#edges",
    "href": "datapre.html#edges",
    "title": "🌊 Data Preparation 🪸",
    "section": "3.2 Edges",
    "text": "3.2 Edges\nThe code chunk below used ExpCATViz() of SmartEDA package to reveal the frequency distribution of all categorical fields in mc3_edges_raw tibble dataframe.\n\nFrequency Distribution of Categorical FieldsFilter by type == sent\n\n\n\n\nShow the code\nExpCatViz(data=mc3_edges_raw,\n          col=\"navyblue\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\nEntities are connected by edges to other Entities via an Event or Relationship node. The one exception to this is the Communication Event subtype, which is additionally linked to either an Event or Relationship node. The type field denotes the connector or edge type for the Entities, Event, and Relationship nodes. The edges are one of these: received, evidence_for, sent, NA.\n\n\n\n\nShow the code\n# Step 1: Filter for type == \"sent\"\nfiltered_edges &lt;- mc3_edges_raw %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(source) %&gt;%\n  arrange(desc(n)) %&gt;%\n  mutate(source = factor(source, levels = rev(unique(source))))  # descending \n\n# Step 2: Plot\nggplot(filtered_edges, aes(x = source, y = n)) +\n  geom_col(fill = \"navy\") +\n  coord_flip() +\n  labs(\n    title = \"Distribution of 'sent' Edges type by Source\",\n    x = \"Source\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nWhat we understood from the information provided by Vast Challenge on Directional Edges:\n\nFor relationship as colleagues node or friends node, the node will have arrows/ edges pointing towards the relationship node.\nFor other relationships and events, the direction would be following the source and target."
  },
  {
    "objectID": "datapre.html#data-cleaning-and-wrangling",
    "href": "datapre.html#data-cleaning-and-wrangling",
    "title": "🌊 Data Preparation 🪸",
    "section": "4.1 Data Cleaning and Wrangling",
    "text": "4.1 Data Cleaning and Wrangling\n\nCleaning and wrangling nodesUnique Node CountCleaning and wrangling edgesUnique Edges CountOther preparatory work\n\n\n\nconvert values in id field into character data type,\nexclude records with id value are na,\nexclude records with similar id values,\nexclude thing_collected , time , date, friendship_type field, and\nsave the cleaned tibble dataframe into a new tibble datatable called mc3_nodes_cleaned.\n\n\n\nShow the code\nmc3_nodes_cleaned &lt;- mc3_nodes_raw %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected, -time, -date, -friendship_type)\n\n\n\n\n\n\n# A tibble: 27 × 2\n   column            unique_count\n   &lt;chr&gt;                    &lt;int&gt;\n 1 id                        1159\n 2 timestamp                  612\n 3 content                    581\n 4 label                       92\n 5 name                        73\n 6 findings                    70\n 7 start_date                  69\n 8 coordination_type           53\n 9 operational_role            35\n10 results                     33\n# ℹ 17 more rows\n\n\n\n\n\nrenamed source and target fields to from_id and to_id respectively,\nconverted values in from_id and to_id fields to character data type,\nexcluded values in from_id and to_id which not found in the id field of mc3_nodes_cleaned,\nexcluded records whereby from_id and/or to_id values are missing, and\nsaved the cleaned tibble dataframe and called it mc3_edges_cleaned.\n\n\n\nShow the code\nmc3_edges_cleaned &lt;- mc3_edges_raw %&gt;%\n  rename(from_id = source,\n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), as.character)) %&gt;%\n  # Parse to_id to get supertype and sub_type for target nodes (e.g., Event_Communication)\n  separate(to_id, into = c(\"to_id_supertype\", \"to_id_sub_type\", \"to_id_num\"),\n           sep = \"_\", remove = FALSE, fill = \"right\", extra = \"merge\") %&gt;%\n  # Filter to ensure from_id and to_id exist in mc3_nodes_cleaned (prevent orphaned edges)\n  filter(from_id %in% mc3_nodes_cleaned$id,\n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\nprint(\"Columns in mc3_edges_cleaned after initial cleaning:\")\n\n\n[1] \"Columns in mc3_edges_cleaned after initial cleaning:\"\n\n\nShow the code\nprint(colnames(mc3_edges_cleaned))\n\n\n[1] \"id\"              \"is_inferred\"     \"from_id\"         \"to_id\"          \n[5] \"to_id_supertype\" \"to_id_sub_type\"  \"to_id_num\"       \"type\"           \n\n\nShow the code\nprint(\"Head of mc3_edges_cleaned after initial cleaning:\")\n\n\n[1] \"Head of mc3_edges_cleaned after initial cleaning:\"\n\n\nShow the code\nprint(head(mc3_edges_cleaned))\n\n\n# A tibble: 6 × 8\n  id    is_inferred from_id to_id to_id_supertype to_id_sub_type to_id_num type \n  &lt;chr&gt; &lt;lgl&gt;       &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;\n1 2     TRUE        Sam     Rela… Relationship    Suspicious     217       &lt;NA&gt; \n2 3     FALSE       Sam     Even… Event           Communication  370       sent \n3 5     TRUE        Sam     Even… Event           Assessment     600       &lt;NA&gt; \n4 3013  TRUE        Sam     Rela… Relationship    Colleagues     430       &lt;NA&gt; \n5 &lt;NA&gt;  TRUE        Sam     Rela… Relationship    Friends        272       &lt;NA&gt; \n6 &lt;NA&gt;  TRUE        Sam     Rela… Relationship    Colleagues     215       &lt;NA&gt; \n\n\n\n\n\n\nShow the code\n# Find the number of unique types in each column\nunique_counts &lt;- mc3_edges_cleaned %&gt;%\n  summarise_all(n_distinct) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"column\", values_to = \"unique_count\")\n\n# Print the unique counts for each column\nprint(unique_counts)\n\n\n# A tibble: 8 × 2\n  column          unique_count\n  &lt;chr&gt;                  &lt;int&gt;\n1 id                      3170\n2 is_inferred                2\n3 from_id                 1052\n4 to_id                   1156\n5 to_id_supertype           71\n6 to_id_sub_type            21\n7 to_id_num                860\n8 type                       4\n\n\n\n\nNext, code chunk below will be used to create mapping of character id in mc3_nodes_cleaned to row index\n\n\nShow the code\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n\nNext, the code chunk below was used to join and convert from_id and to_id to integer indices. At the same time we also dropped rows with unmatched nodes.\n\n\nShow the code\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  # Filter out edges where either source or target node was not found\n  filter(!is.na(from) & !is.na(to)) %&gt;%\n  # Select all columns to carry forward to mc3_edges_final\n  select(from, to, id, is_inferred, type, # Original edge attributes\n         from_id, to_id, to_id_supertype, to_id_sub_type, to_id_num # Original IDs and parsed target type\n         )\n\n\nNext the code chunk below was used to subset nodes to only those referenced by edges.\n\n\nShow the code\nused_node_indices &lt;- sort(unique(c(mc3_edges_indexed$from, mc3_edges_indexed$to)))\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n\nWe then used the code chunk below to rebuild lookup from old index to new index.\n\n\nShow the code\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(used_node_indices)\n)\n\n\nLastly, the code chunk below was used to update edge indices to match new node table.\n\n\nShow the code\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  # Explicitly select all columns that are needed downstream\n  select(from = from_new, to = to_new,\n         id, is_inferred, type,\n         from_id, to_id, to_id_supertype, to_id_sub_type, to_id_num)"
  },
  {
    "objectID": "datapre.html#building-the-tidygraph-object",
    "href": "datapre.html#building-the-tidygraph-object",
    "title": "🌊 Data Preparation 🪸",
    "section": "4.2 Building the tidygraph object",
    "text": "4.2 Building the tidygraph object\n\nBuild the object-tbl_graphExamining the object\n\n\n\n\nShow the code\nmc3_graph &lt;- tbl_graph(\n  nodes = mc3_nodes_final,\n  edges = mc3_edges_final,\n  directed = TRUE\n)\n\n\n\n\n\n\nShow the code\nstr(mc3_graph)\n\n\nClasses 'tbl_graph', 'igraph'  hidden list of 10\n $ : num 1159\n $ : logi TRUE\n $ : num [1:3226] 0 0 0 0 0 0 0 1 1 1 ...\n $ : num [1:3226] 1137 356 746 894 875 ...\n $ : NULL\n $ : NULL\n $ : NULL\n $ : NULL\n $ :List of 4\n  ..$ : num [1:3] 1 0 1\n  ..$ : Named list()\n  ..$ :List of 28\n  .. ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  .. ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  .. ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  .. ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ findings         : chr [1:1159] NA NA NA NA ...\n  .. ..$ content          : chr [1:1159] NA NA NA NA ...\n  .. ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ results          : chr [1:1159] NA NA NA NA ...\n  .. ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ destination      : chr [1:1159] NA NA NA NA ...\n  .. ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  .. ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  .. ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  .. ..$ reference        : chr [1:1159] NA NA NA NA ...\n  .. ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  .. ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  .. ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  .. ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  .. ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  .. ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ operational_role : chr [1:1159] NA NA NA NA ...\n  .. ..$ new_index        : int [1:1159] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ :List of 8\n  .. ..$ id             : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  .. ..$ is_inferred    : logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  .. ..$ type           : chr [1:3226] NA \"sent\" NA NA ...\n  .. ..$ from_id        : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  .. ..$ to_id          : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  .. ..$ to_id_supertype: chr [1:3226] \"Relationship\" \"Event\" \"Event\" \"Relationship\" ...\n  .. ..$ to_id_sub_type : chr [1:3226] \"Suspicious\" \"Communication\" \"Assessment\" \"Colleagues\" ...\n  .. ..$ to_id_num      : chr [1:3226] \"217\" \"370\" \"600\" \"430\" ...\n $ :&lt;environment: 0x7fed20b2d7d0&gt; \n - attr(*, \"active\")= chr \"nodes\""
  },
  {
    "objectID": "datapre.html#visnetwork",
    "href": "datapre.html#visnetwork",
    "title": "🌊 Data Preparation 🪸",
    "section": "VisNetwork",
    "text": "VisNetwork\nVisNetwork provides the user to understand relationships through interactivity. For instance:\n\nThe individual nodes can be selected from the drop-down menu to view its connected nodes and edges.\nThe hover tooltip provides additional details from fields such as content, coordination_type, findings, destination, operational_role, results, and jurisdiction_type based on the related id information from mc3_nodes_final."
  },
  {
    "objectID": "datapre.html#the-graph--visnetwork",
    "href": "datapre.html#the-graph--visnetwork",
    "title": "🌊 Data Preparation 🪸",
    "section": "The Graph- VisNetwork",
    "text": "The Graph- VisNetwork\n\n\n\n\n\n\n\n\n\n\nShow the code\n# ---- 1. Define styles and legends ----\n\nevent_subtypes &lt;- c(\n  \"Communication\", \"Monitoring\", \"VesselMovement\", \"Assessment\",\n  \"Collaborate\", \"Endorsement\", \"TourActivity\", \"TransponderPing\",\n  \"Harbor Report\", \"Fishing\", \"Criticize\"\n)\n\nrelationship_subtypes &lt;- c(\n  \"Coordinates\", \"AccessPermission\", \"Operates\", \"Colleagues\",\n  \"Suspicious\", \"Reports\", \"Jurisdiction\", \"Unfriendly\", \"Friends\"\n)\n\nnode_legend_colors_plot &lt;- c(\n  \"Person\" = \"#88CCEE\",\n  \"Vessel\" = \"#D55E00\",\n  \"Organization\" = \"#117733\",\n  \"Location\" = \"#AA4499\",\n  \"Group\"= \"#CC79A7\",\n  \"Event\" = \"#DDCC77\",         # type level\n  \"Relationship\" = \"#AF8DC3\"   # type level\n)\n\nnode_legend_shapes_plot &lt;- c(\n  \"Person\" = \"dot\",\n  \"Vessel\" = \"triangle\",\n  \"Organization\" = \"square\",\n  \"Location\" = \"diamond\",\n  \"Group\" = \"circle plus\",\n  \"Event\" = \"star\",              # type level\n  \"Relationship\" = \"square x\"    # type level\n)\n\nSTYLES &lt;- list(\n  node_label_dark = \"black\",\n  font_family = \"Roboto Condensed\"\n)\n\n# ---- 2. Prepare nodes ----\nnodes &lt;- mc3_nodes_final %&gt;%\n  mutate(\n    label = ifelse(is.na(name), id, name),\n    \n    # These parts are for pulling the related data from other fields\n    tooltip_extra = case_when(\n      type == \"Event\" & sub_type == \"Communication\" ~ content,\n      type == \"Event\" & sub_type == \"Monitoring\" ~ findings,\n      type == \"Event\" & sub_type == \"VesselMovement\" ~ destination,\n      type == \"Event\" & sub_type == \"Assessment\" ~ results,\n      type == \"Relationship\" & sub_type == \"Coordinates\" ~ coordination_type,\n      type == \"Relationship\" & sub_type == \"Operates\" ~ operational_role,\n      type == \"Relationship\" & sub_type == \"Jurisdiction\" ~ jurisdiction_type,\n      TRUE ~ NA_character_\n    ),\n    \n    title = paste0(\n      \"&lt;b&gt;\", label, \"&lt;/b&gt;&lt;br&gt;\",\n      \"Type: \", type, \"&lt;br&gt;\",\n      \"Sub-type: \", sub_type, \"&lt;br&gt;\",\n      ifelse(!is.na(tooltip_extra), paste0(\"&lt;br&gt;&lt;b&gt;Details:&lt;/b&gt; \", tooltip_extra), \"\")\n    ),\n    \n    # Fallback logic: if sub_type is NA or not in styling list, use type instead\n    group = ifelse(sub_type %in% names(node_legend_colors_plot), sub_type, type)\n  ) %&gt;%\n  select(id, label, group, title) %&gt;%\n  distinct()\n\n# ---- 3. Prepare directed edges (type == \"sent\") ----\n\nedges &lt;- mc3_edges_final %&gt;%\n  filter(from_id %in% nodes$id & to_id %in% nodes$id) %&gt;%\n  select(from = from_id, to = to_id)\n\n# ---- 4. Build visNetwork ----\n\nnet &lt;- visNetwork(nodes, edges, width = \"100%\", height = \"600px\") %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 1.5))) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visNodes(font = list(\n    size = 14,\n    color = STYLES$node_label_dark,\n    face = STYLES$font_family,\n    vadjust = -15\n  ))\n\n# ---- 5. Apply shape and color per group ----\n\nfor (group_name in names(node_legend_colors_plot)) {\n  net &lt;- net %&gt;% visGroups(\n    groupname = group_name,\n    color = node_legend_colors_plot[[group_name]],\n    shape = node_legend_shapes_plot[[group_name]]\n  )\n}\n# ---- 6. Add legend ----\n\nused_groups &lt;- unique(nodes$group)\n\nlegend_df &lt;- tibble::tibble(\n  label = used_groups,\n  shape = node_legend_shapes_plot[used_groups],\n  color = node_legend_colors_plot[used_groups]\n) %&gt;%\n  distinct(label, .keep_all = TRUE)  # remove duplicates just in case\n\nnet &lt;- net %&gt;% visLegend(\n  addNodes = legend_df,\n  ncol = 2,                         # number of columns\n  position = \"left\",              \n  main = \"Entity (Sub)Types\",      # title\n  useGroups = FALSE                # show custom legend entries\n)\n# ---- 7. Render ----\nnet"
  }
]